<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lab: 8 Machine Learning for Classification | FRST 538: Advanced Geomatics for Natural Resource Management</title>
  <meta name="description" content="Open Educational Resources for FRST 538 course at the University of British Columbia" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Lab: 8 Machine Learning for Classification | FRST 538: Advanced Geomatics for Natural Resource Management" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Open Educational Resources for FRST 538 course at the University of British Columbia" />
  <meta name="github-repo" content="github.com/ubc-geomatics-community-of-practice/FRST538-Advanced-Geomatics-for-Natural-Resource-Management/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lab: 8 Machine Learning for Classification | FRST 538: Advanced Geomatics for Natural Resource Management" />
  
  <meta name="twitter:description" content="Open Educational Resources for FRST 538 course at the University of British Columbia" />
  

<meta name="author" content="Paul D. Pickell" />


<meta name="date" content="2024-11-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="time-series-image-analysis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">An Open Geomatics Community of Practice</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-these-resources"><i class="fa fa-check"></i>How to use these resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-get-involved"><i class="fa fa-check"></i>How to get involved</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="network-analysis.html"><a href="network-analysis.html"><i class="fa fa-check"></i><b>1</b> Salmon Stream Network Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#lab-overview"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#lab1-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#data"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#task-1-create-stream-segments"><i class="fa fa-check"></i>Task 1: Create stream segments</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#task-2-create-routes-and-apply-topology"><i class="fa fa-check"></i>Task 2: Create routes and apply topology</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#task-3-record-stream-attributes-with-linear-referencing"><i class="fa fa-check"></i>Task 3: Record stream attributes with linear referencing</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#task-4-trace-the-network"><i class="fa fa-check"></i>Task 4: Trace the network</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#task-5-overlay-and-query-the-network"><i class="fa fa-check"></i>Task 5: Overlay and query the network</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#final-report"><i class="fa fa-check"></i>Final Report</a></li>
<li class="chapter" data-level="" data-path="network-analysis.html"><a href="network-analysis.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lidar-terrain.html"><a href="lidar-terrain.html"><i class="fa fa-check"></i><b>2</b> LiDAR, terrain models and geovisualization</a>
<ul>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#lab-overview-1"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#learning-objectives-1"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#lab2-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#lab2-data"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-1-load-and-explore-the-lidar-data"><i class="fa fa-check"></i>Task 1: Load and explore the LiDAR data</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-2-create-a-dtm-using-built-in-arcgis-functions"><i class="fa fa-check"></i>Task 2: Create a DTM using built-in ArcGIS functions</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-3-pre-process-data-for-interpolation"><i class="fa fa-check"></i>Task 3: Pre-process data for interpolation</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-4-raster-interpolation"><i class="fa fa-check"></i>Task 4: Raster interpolation</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-5-visually-interpret-differences"><i class="fa fa-check"></i>Task 5: Visually interpret differences</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-6-quantitatively-interpret-the-differences-and-calculate-statistics-for-each-zone"><i class="fa fa-check"></i>Task 6: Quantitatively interpret the differences and calculate statistics for each zone</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-7-create-a-map-document"><i class="fa fa-check"></i>Task 7: Create a map document</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#task-8-exploring-scenes"><i class="fa fa-check"></i>Task 8: Exploring Scenes</a></li>
<li class="chapter" data-level="" data-path="lidar-terrain.html"><a href="lidar-terrain.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html"><i class="fa fa-check"></i><b>3</b> Suitability and Overlay Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#lab-overview-2"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#learning-objectives-2"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#lab3-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#data-1"><i class="fa fa-check"></i>Data</a>
<ul>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#data-organization"><i class="fa fa-check"></i>Data Organization</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#files-to-create"><i class="fa fa-check"></i>Files to Create</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#task-1-export-relevant-data-from-biologically-important-areas"><i class="fa fa-check"></i>Task 1: Export Relevant Data from Biologically Important Areas</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#task-2-identify-the-bia-of-the-humpback-whale-that-is-not-within-the-established-marine-sanctuary"><i class="fa fa-check"></i>Task 2: Identify the BIA of the Humpback Whale that is not within the established Marine Sanctuary</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#task-3-calculate-the-density-of-cetacean-sightings-using-the-bia-for-humpback-whales"><i class="fa fa-check"></i>Task 3: Calculate the Density of Cetacean Sightings using the BIA for Humpback Whales</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#task-4-extract-the-boats-from-ocean-uses-and-identity-the-vessels-within-the-bia-polygons"><i class="fa fa-check"></i>Task 4: Extract the Boats from Ocean Uses and Identity the Vessels within the BIA Polygons</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#task-5-calculate-suitability-and-identify-most-suitable-locations-for-the-marine-sanctuary"><i class="fa fa-check"></i>Task 5: Calculate Suitability and Identify Most Suitable Locations for the Marine Sanctuary</a></li>
<li class="chapter" data-level="" data-path="suitability-overlay-analysis.html"><a href="suitability-overlay-analysis.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html"><i class="fa fa-check"></i><b>4</b> Analyzing Green Equity Using Geographically Weighted Regression</a>
<ul>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#lab-overview-3"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#learning-objectives-3"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#lab4-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#lab4-data"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#task-1-visualize-census-data"><i class="fa fa-check"></i>Task 1: Visualize census data</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#task-2-calculate-ndvi-from-a-landsat-satellite-image"><i class="fa fa-check"></i>Task 2: Calculate NDVI from a Landsat satellite image</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#task-3-model-ndvi-using-census-characteristics"><i class="fa fa-check"></i>Task 3: Model NDVI using census characteristics</a>
<ul>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#ordinary-least-square-regression"><i class="fa fa-check"></i>Ordinary Least Square Regression</a></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#geographically-weighted-regression-1"><i class="fa fa-check"></i>Geographically Weighted Regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="geographically-weighted-regression.html"><a href="geographically-weighted-regression.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="spectral-signatures.html"><a href="spectral-signatures.html"><i class="fa fa-check"></i><b>5</b> Getting to know Remote Sensing and spectral signatures</a>
<ul>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#lab-overview-4"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#learning-objectives-4"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#lab5-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#data-2"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#task-1-the-electromagnetic-spectrum"><i class="fa fa-check"></i>Task 1: The Electromagnetic Spectrum</a></li>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#task-2-landsat-5-bands-the-ems-arcgis-pro-software"><i class="fa fa-check"></i>Task 2: Landsat 5 Bands, the EMS, &amp; ArcGIS Pro Software</a></li>
<li class="chapter" data-level="" data-path="spectral-signatures.html"><a href="spectral-signatures.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html"><i class="fa fa-check"></i><b>6</b> Lidar for Forest Management</a>
<ul>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#lab-overview-5"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#learning-objectives-5"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#lab6-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#data-3"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#lab-set-up"><i class="fa fa-check"></i>Lab Set up</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-1-load-rgb-imagery"><i class="fa fa-check"></i>Task 1: Load RGB Imagery</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-2-load-and-explore-the-lidar-data"><i class="fa fa-check"></i>Task 2: Load and Explore the LiDAR Data</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-3-read-multiple-las-files-into-lascatolog-object"><i class="fa fa-check"></i>Task 3: Read Multiple LAS Files into LAScatolog object</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-4-create-digital-elevation-model-dem"><i class="fa fa-check"></i>Task 4: Create Digital Elevation Model (DEM)</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-5-create-a-canopy-height-model"><i class="fa fa-check"></i>Task 5: Create a Canopy Height Model</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-6-extract-metrics-from-the-point-clouds"><i class="fa fa-check"></i>Task 6: Extract Metrics From the Point Clouds</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#task-7-individual-tree-detection"><i class="fa fa-check"></i>Task 7: Individual Tree Detection</a></li>
<li class="chapter" data-level="" data-path="lidar-for-forest-management.html"><a href="lidar-for-forest-management.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html"><i class="fa fa-check"></i><b>7</b> Time Series Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#lab-overview-6"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#learning-objectives-6"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#lab7-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#data-4"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#task-1-starting-arcgis-pro"><i class="fa fa-check"></i>Task 1: Starting ArcGIS Pro</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#toggling-extentions"><i class="fa fa-check"></i>Toggling Extentions</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#inserting-a-new-map"><i class="fa fa-check"></i>Inserting a New Map</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#adding-data-to-the-map"><i class="fa fa-check"></i>Adding Data to the Map</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#task-1-calculating-ndvi"><i class="fa fa-check"></i>Task 1: Calculating NDVI</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#task-2-time-series-analysis"><i class="fa fa-check"></i>Task 2: Time Series Analysis</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#task-3-change-detection"><i class="fa fa-check"></i>Task 3: Change Detection</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#task-4-map-creation"><i class="fa fa-check"></i>Task 4: Map Creation</a></li>
<li class="chapter" data-level="" data-path="time-series-image-analysis.html"><a href="time-series-image-analysis.html#summary-6"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html"><i class="fa fa-check"></i><b>8</b> Machine Learning for Classification</a>
<ul>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#lab-overview-7"><i class="fa fa-check"></i>Lab Overview</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#learning-objectives-7"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#lab8-deliverables"><i class="fa fa-check"></i>Deliverables</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#data-5"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#task-1-creating-training-data"><i class="fa fa-check"></i>Task 1: Creating training data</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#task-2-training-a-random-forest-random-forest-algorithm"><i class="fa fa-check"></i>Task 2: Training a Random Forest (Random Forest Algorithm)</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#task-3-interpreting-classification-results"><i class="fa fa-check"></i>Task 3: Interpreting Classification Results</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#task-4-making-a-map"><i class="fa fa-check"></i>Task 4: Making a Map</a></li>
<li class="chapter" data-level="" data-path="machine-learning-for-classification.html"><a href="machine-learning-for-classification.html#summary-7"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">FRST 538: Advanced Geomatics for Natural Resource Management</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning-for-classification" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Lab: 8</span> Machine Learning for Classification<a href="machine-learning-for-classification.html#machine-learning-for-classification" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Written by
Claire Armour</p>
<div id="lab-overview-7" class="section level2 unnumbered hasAnchor">
<h2>Lab Overview<a href="machine-learning-for-classification.html#lab-overview-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this lab you will learn about supervised classification and selecting training and validation data. You will be classifying a Landsat 8 OLI image representing Vancouver and the surrounding area using ArcGIS Pro. You will then assess the accuracy of your classification.</p>
<hr />
</div>
<div id="learning-objectives-7" class="section level2 unnumbered hasAnchor">
<h2>Learning Objectives<a href="machine-learning-for-classification.html#learning-objectives-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Understand the four steps of supervised classification</li>
<li>Use the Classification wizard in ArcGIS pro to create classes</li>
<li>Choose representive training regions based on classes</li>
<li>Train a random forest model using training data</li>
<li>Interpret a confusion matrix and inspect the classification visually to assess classified map accuracy</li>
</ul>
<hr />
</div>
<div id="lab8-deliverables" class="section level2 unnumbered hasAnchor">
<h2>Deliverables<a href="machine-learning-for-classification.html#lab8-deliverables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><input type="checkbox" unchecked> PDF report with the answers to all of the lab questions, the required screen shots and maps. </input></p>
<hr />
</div>
<div id="data-5" class="section level2 unnumbered hasAnchor">
<h2>Data<a href="machine-learning-for-classification.html#data-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The data for this lab consist of a single Landsat 8 OLI Image of the greater Vancouver Area, southern Vancouver island and northern Washington; “LC80470262021149LGN00”. The imagery was acquired May 29th 2021. The band designations for Land 8 OLI is as follows:</p>
<p><img src="images/08-landsat-designations.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Note: Because we are using Landsat 8 imagery the bands are different than the ones you have used in previous labs.<br />
A 2015 Landcover layer will be used as a validation dataset. Information on this data set is available <a href="http://www.cec.org/north-american-environmental-atlas/land-cover-30m-2015-landsat-and-rapideye/">here:</a></p>
<p>The table below shows the legend for converting between the raster values and actual landcover types.</p>
<p><img src="images/08-raster-value-table.png" width="100%" style="display: block; margin: auto;" /></p>
<hr />
</div>
<div id="task-1-creating-training-data" class="section level2 unnumbered hasAnchor">
<h2>Task 1: Creating training data<a href="machine-learning-for-classification.html#task-1-creating-training-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The goal of a supervised classification is to manually identify sample training areas, each representing a land-cover class in a remote sensing image, and use a classification algorithm to automatically classify all of the pixels in the image into these classes. There are four key steps with supervised classifications:</p>
<p><strong>1. Defining information classes</strong></p>
<p><strong>2. Identifying training areas</strong></p>
<p><strong>3. Defining spectral signatures for classes of interest</strong></p>
<p><strong>4. Applying the classification algorithm</strong></p>
<p><strong>Defining information classes</strong>- The first step of a supervised classification is to decide what classes to use. This includes deciding how many classes to use and what they represent. These classes should include the main features of interest in your remote sensing image. This step takes some serious thought, and the success of your classification depends on choosing good classes. The detail of the classes you choose is related to the spatial and radiometric resolution of the data you are using. For example, given a very high spatial resolution image, you may be able to classify individual tree crowns and shrubs; however, given a more moderate spatial resolution image, you may have more success classifying broad forest types (for example, conifer forest and broadleaf forest). Remember, the more similar the pixels are within classes and the more different the pixels are between classes, the better the classification will work.</p>
<p><strong>Identifying training areas</strong> - The second step in a supervised classification is collecting “training areas”. This involves drawing boundaries around a number of sample areas that represent the land-cover classes. The idea is that you are manually classifying a subset of pixels, and the classification algorithm will use these training areas to classify all of the other pixels in the image. Each class will have a number of training areas, ideally sufficient to represent the range of pixel values for each land-cover across the entire image. The location of training areas may be determined in the field using GPS; interpreted from remotely sensed data; or from other sources (such as existing maps).</p>
<p><strong>Defining the spectral signatures for the classes</strong> - The third step is to calculate training statistics for the pixels in each land-cover class. Some of these statistics include: minimum, maximum, mean, standard deviation for the digital numbers of each band for each class. These statistics are used to assign membership to a class/category (land-cover type) for each and every image pixel in the remote sensing scene using an image classification algorithm (e.g., Maximum Likelihood).</p>
<p><strong>Applying the classification algorithm</strong>-The fourth and final step is to assess the accuracy of the classification. Accuracy assessment is crucial, for any map that is produced.</p>
<p>To begin <strong>Open</strong> ArcGIS Pro and create a new Project called “LabML_yourName” and save it in your lab folder. Navigate to the Catalog and open the “LC08_L1TP_047026_20210529_2.tif” file in map view. This file is a raster layer stack representing 8 bands/channels of Landsat 8 OLI imagery acquired May 29th 2021; where each band corresponds to the table above in the Data description except band_8 = Cirrus.</p>
<div id="q1-landsat-oli-bands-8-10-and-11-were-not-included-in-the-provided-layer-and-therefore-purposefully-excluded-from-this-classification-and-excersise.-what-portion-of-the-electromagnetic-spectrum-do-these-bands-represent-and-why-do-you-think-they-were-not-included" class="section level5 unnumbered hasAnchor">
<h5>Q1: Landsat OLI Bands 8, 10, and 11 were not included in the provided layer and therefore purposefully excluded from this classification and excersise. What portion of the electromagnetic spectrum do these bands represent, and why do you think they were not included?<a href="machine-learning-for-classification.html#q1-landsat-oli-bands-8-10-and-11-were-not-included-in-the-provided-layer-and-therefore-purposefully-excluded-from-this-classification-and-excersise.-what-portion-of-the-electromagnetic-spectrum-do-these-bands-represent-and-why-do-you-think-they-were-not-included" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Navigate to the <strong>Symbology</strong> pane and from the available bands list display an RGB colour composite, using bands_2 (blue), band_3 (green) and band_4 (red). Start by having a look around the scene and in the <strong>Appearance</strong> ribbon feel free to change the Stretch Type, Contrast, Brightness and Gamma until you are happy with how you scene looks. As you are working on this assignment you are encouraged to load different band combinations and enhancements to highlight the features that you are interested in. For example, a False Colour Composite using Red= NIR Band, Green = Red Band, Blue = Green Band is particularly useful for looking at vegetation (Figure 1).</p>
<p><img src="images/08-false-colour-composite.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Figure 1: False colour composite.</p>
<p>To perform supervised classification of digital remotely sensed data, training (calibration) data are required to provide examples of the statistical values representing particular land-cover classes. In addition to training (calibration) data, testing (validation) data are also required to assess the accuracy of the classification. Validation data are of the same nature as calibration data, however they are independent datasets.</p>
<p>We are going to classify the 2021 Landsat 8 OLI image by defining training areas for a number of land-cover categories. Remember that a land-cover class is only realistic if it is spectrally unique and observable at the spatial and spectral resolution of the imagery. In other words, the spatial and spectral resolution of Landsat imagery in most cases allow for distinguishing between taxonomic tree types, such as broadleaf and coniferous, but do not permit separating
specific tree species, such as Douglas-fir and Western redcedar. Therefore, defining broadleaf and conifer as target land-cover categories is practical and achievable, as these are realistic spectral classes, whereas classes based on specific tree species (such as distinguishing between Douglas-fir and Western redcedar) are unrealistic as these divisions are not spectrally distinguishable.</p>
<p>When considering Landsat imagery, beyond forests, other types of vegetation can be distinguished. For instance, often times, areas dominated by herbs, shrubs and/or agricultural growth will appear spectrally different to forests in Landsat imagery; however, these non-forest vegetation types may appear spectrally similar to each other. An exception to this relates to vegetation health, which can be associated with things such as stress (due to water shortage and/or pest infestation). Furthermore, time of year is important. Due to phenological properties vegetation may appear very differently in July vs. January.</p>
<p>Beyond vegetation, other types of land-cover features are spectrally identifiable in Landsat imagery. For example, these may include classes relatable to water and human-made features (for example, urban development).</p>
<p>ArcGIS PRO has a convenient built in <strong>Classification Wizard</strong> that we will be using for this lab to develop our training data. Ensure that the “LC08_L1TP_047026_20210529_2.tif” layer in selected in the contents pane and then navigate to the “Imagery” ribbon and select <strong>Classification Wizard</strong>. Under “Classification Method” select <strong>Supervised</strong>, for “Classification Type” select <strong>Pixel Based</strong>, for “Classification Schema” use the drop-down menu on the side and select Browse to <strong>Existing Schema</strong> and navigate to the NALCMSC.ecs file in your data folder should appear in the window. Under <strong>Optional</strong> select the 2015_NALCMS_LC.tif data set.</p>
<p><img src="images/08-image-classification-wizard.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Select the Lab Project folder as your “Output Location” and select <strong>Next</strong> at the bottom of the Image Classification Wizard pane. The “Training Samples Manager” should appear and you should see something similar to the image below.</p>
<p><img src="images/08-nalcms-simple-classes.png" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="q5-using-what-you-have-learned-about-classification-is-there-a-landcover-class-that-is-not-appropriate-for-the-current-sensor-and-study-area-why" class="section level5 unnumbered hasAnchor">
<h5>Q5: Using what you have learned about classification is there a landcover class that is not appropriate for the current sensor and study area? why?<a href="machine-learning-for-classification.html#q5-using-what-you-have-learned-about-classification-is-there-a-landcover-class-that-is-not-appropriate-for-the-current-sensor-and-study-area-why" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Remove this class from the training sample manager by left clicking on this class and pressing the red X button.</p>
</div>
<div id="q6-using-the-provided-image-hypothesize-at-least-three-additional-possible-classes." class="section level5 unnumbered hasAnchor">
<h5>Q6: Using the provided image hypothesize at least three additional possible classes.<a href="machine-learning-for-classification.html#q6-using-the-provided-image-hypothesize-at-least-three-additional-possible-classes." class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>It is now time to create your training data set. In this lab we will create our own training samples using the training sample manager. In your own research you may have field plots or polygons that you can import. Before we begin there are a few things to keep in mind as you create your training data:</p>
<ul>
<li>For every land cover class, you need to have multiple polygons. It is better (and required!) to have numerous small class specific training areas spread out throughout the image than it is to have only a couple of very large training areas.</li>
<li>To capture class variability, you should have at least 10 different polygons per class as spread throughout the image as much as possible.</li>
<li>For Needleleaf Forest, Cropland, Barren Land, Urban and Built Up, Water, Snow and Ice you are required to have 10 polygons per class.</li>
<li>For all other classes, you are Required to have 5 polygons per class.</li>
</ul>
<p>It will take some time to delineate all necessary training samples. Get comfortable, and get into it. Know your imagery. Feel free to use google maps and other software to hunt for areas if it helps.</p>
<p>To begin select the first class you want to draw a training area from and press the <strong>Rectangle</strong> button and draw a polygon over the proper class. Do this for the required amount of polygons for each class.</p>
<p><img src="images/08-rectangle-training-areas.png" width="50%" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="task-2-training-a-random-forest-random-forest-algorithm" class="section level2 unnumbered hasAnchor">
<h2>Task 2: Training a Random Forest (Random Forest Algorithm)<a href="machine-learning-for-classification.html#task-2-training-a-random-forest-random-forest-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When you have finished creating your training polygons. Select <strong>Next</strong> at the bottom of your window. The “Train” window should appear. Under “Classifier” Select <strong>Random Trees</strong> and leave the other options has default. Press <strong>Run</strong> and a preview of your classified raster should appear. Look it over, if you are happy with the classification select <strong>Next</strong>, if not select <strong>previous</strong> and add more training data. The “Classify” pane should appear, under “Output Classified Dataset” write “Random_Trees_Classification” leave the rest blank and select Run at the bottom. After the Classification has run select <strong>Next</strong> and then press <strong>Next</strong> again in the “Merge Classes” pane. In the “Accuracy Assessment” window leave the default settings for “Number of Random Points” and change “Sampling Strategy” to <strong>Equalized Stratified Random</strong>, change the “Output Confusion Matrix” to ConfusionMatrix_RF and press <strong>Run</strong>. After Completion a small coloured grid should appear, you can hover over the squares to see your confusion matrix statistics. Don’t worry too much about this as we will explore the Confusion matrix more in the next steps.</p>
<p><img src="images/08-confusion-matrix.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Click <strong>Next</strong> and proceed to the final portion of the “Image Classification Wizard”. After you classify an image, there can be small errors in the classification result. To address these, it is often easier to edit the final classified image rather than re-create training sites and perform each step in the classification again. The <strong>Reclassifier</strong> page allows you to make edits to individual features or objects in the classified image. We will skip this step in this lab and move on to interpreting our confusion matrix.</p>
<div id="q4-describe-2-sentences-the-random-trees-algorithm-process-and-key-outputs." class="section level5 unnumbered hasAnchor">
<h5>Q4: Describe (2 sentences) the random trees algorithm process and key outputs.<a href="machine-learning-for-classification.html#q4-describe-2-sentences-the-random-trees-algorithm-process-and-key-outputs." class="anchor-section" aria-label="Anchor link to header"></a></h5>
<hr />
</div>
</div>
<div id="task-3-interpreting-classification-results" class="section level2 unnumbered hasAnchor">
<h2>Task 3: Interpreting Classification Results<a href="machine-learning-for-classification.html#task-3-interpreting-classification-results" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All image classifications will contain misclassification. There is no such thing as a perfectly classified map. The accuracy and therefore usability of a classified map depends on many factors, including the original data used (i.e., the remotely sensed data), and the nature of the training and testing data.
To assess the accuracy of your map we will do a visual assessment and a standard confusion matrix. The confusion matrix is a cross-tabulation of the mapped class labels (i.e., land-cover categories) against independent validation data. The confusion matrix measures the percentage of cases correctly allocated overall (i.e., overall accuracy), the Kappa index of agreement and the percentage of cases correctly allocated per class (i.e, producer’s and user’s accuracies). Kappa analysis is conducted to determine if individual classifications are significantly better than random classifications and if any two classifications are significantly different. Producer’s accuracy assesses if there are instances when cases in a class are omitted from a class they should have been mapped as (i.e., omission error). User’s accuracy assesses if there are instances when cases in a class are committed to a class they were known not to belong to (i.e., commission error).</p>
<p><strong>Note:</strong> If your map exhibits high levels of misclassification, it is likely that the training areas are not appropriate/not truly representative of the full spectral range of a class. It is also possible that some of the classes you are attempting to map may not in actuality be spectrally distinct and therefore may not be appropriate. If there were high levels of misclassification associated with a particular class, you would want to evaluate the appropriateness of this class and/or whether you have truly captured the spectral variability of the class. It is not unusual to add and remove a number of classes and/or “tweak” the classes that you have and rerun the classification algorithm a number of times before satisfactory results are achieved.</p>
<p>Scroll to the bottom of the <strong>Contents</strong> pane and right click “ConfusionMatrix_RF” and select <strong>Open</strong>. A window should appear with your Confusion Matrix that look something like this (Although your values should be different).</p>
<p><img src="images/08-confusion-matrix-table.png" width="80%" style="display: block; margin: auto;" /></p>
<p>While this table works it isn’t very readable. Right click on “ConfusionMatix_RF” go down to <strong>Data</strong> and select <strong>Export Table</strong>. Export your table as a .csv file type and open in Microsoft Excel (or your table editor of choice) and create readable confusion matrix .</p>
<p><img src="images/08-desired-confusion-matrix.png" width="80%" style="display: block; margin: auto;" /></p>
<div id="screenshot-1-submit-a-screen-shot-of-your-formated-confusion-matrix." class="section level5 unnumbered hasAnchor">
<h5>Screenshot 1: Submit a screen shot of your formated confusion matrix.<a href="machine-learning-for-classification.html#screenshot-1-submit-a-screen-shot-of-your-formated-confusion-matrix." class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
<div id="q5-describe-producers-and-users-accuracy" class="section level5 unnumbered hasAnchor">
<h5>Q5: Describe producer’s and user’s accuracy<a href="machine-learning-for-classification.html#q5-describe-producers-and-users-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
<div id="q6-which-class-has-the-highest-producers-accuracy-why" class="section level5 unnumbered hasAnchor">
<h5>Q6: Which class has the highest producers accuracy? Why?<a href="machine-learning-for-classification.html#q6-which-class-has-the-highest-producers-accuracy-why" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
<div id="q7-which-class-has-the-lowest-producers-accuracy-why-what-class-was-it-most-often-confused-with" class="section level5 unnumbered hasAnchor">
<h5>Q7: Which class has the lowest producers accuracy? Why? What class was it most often confused with?<a href="machine-learning-for-classification.html#q7-which-class-has-the-lowest-producers-accuracy-why-what-class-was-it-most-often-confused-with" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We will now be using the <strong>swipe</strong> feature to conduct a visual accuracy assessment. Ensure your Classification layer is the top layer in the “Drawing Order” tab in the “Contents” pane and that the NALCMS_LC_2015 layer is second. Select your classified layer and navigate to the “Appearance” ribbon and select the <strong>Swipe</strong> button. Hover your cursor over the map scene and it should have turned into an arrow click and drag the arrow up and down or across your Map pane to switch between the two layers.</p>
<p><img src="images/08-visual-accuracy-assessment.png" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="q8-do-you-think-that-your-confusion-matrix-corresponds-to-your-visual-accuracy-assessement-why-or-why-not-are-there-any-classes-you-thougth-would-be-more-difficult-to-differentiate-between-explain." class="section level5 unnumbered hasAnchor">
<h5>Q8: Do you think that your confusion matrix corresponds to your visual accuracy assessement? Why or why not? Are there any classes you thougth would be more difficult to differentiate between? Explain.<a href="machine-learning-for-classification.html#q8-do-you-think-that-your-confusion-matrix-corresponds-to-your-visual-accuracy-assessement-why-or-why-not-are-there-any-classes-you-thougth-would-be-more-difficult-to-differentiate-between-explain." class="anchor-section" aria-label="Anchor link to header"></a></h5>
<hr />
</div>
</div>
<div id="task-4-making-a-map" class="section level2 unnumbered hasAnchor">
<h2>Task 4: Making a Map<a href="machine-learning-for-classification.html#task-4-making-a-map" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now is the time for your cartographic skills to shine. To design a map of the highest quality you will need to draw on all of you GIS skills. Ensure you include all the standard components of a map along with your artistic flair.</p>
<p>If you need some inspiration a quick google search for “Design principles for cartography” or browsing through some of the maps featured <a href="https://livingatlas.arcgis.com/en/home/">here</a> should do the trick.</p>
<p>You should design a map that shows the output of your random tree’s classification. Feel free to use inset maps to show areas differed from the reference dataset.</p>
<p>Also, be sure to include important data, but also make sure the map is not too cluttered.
The physical requirements are as follows:</p>
<ul>
<li><p>Map should be 11”x17” either as a landscape or portrait layout</p></li>
<li><p>You should export the map as a pdf</p></li>
<li><p>Your map should incorporate the suite of standard map element:</p>
<ul>
<li><p>Title</p></li>
<li><p>Scale bar</p></li>
<li><p>Compass</p></li>
<li><p>Legend</p></li>
</ul></li>
</ul>
<hr />
</div>
<div id="summary-7" class="section level2 unnumbered hasAnchor">
<h2>Summary<a href="machine-learning-for-classification.html#summary-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this lab, you will conduct a supervised classification of a remote sensing image. The process involves four key steps: defining information classes, identifying training areas, defining spectral signatures, and applying a classification algorithm. You’ll start by defining land-cover classes relevant to your image, followed by manually selecting training areas that represent these classes. Next, you will create a random forest model to classify the full image. Machine learning plays a crucial role in this process by automating and improving the accuracy of the classification, enabling more efficient and reliable analysis. Finally, you’ll assess the accuracy of the classification using visual interpretation and confusion matrix to ensure dependable results.</p>
<p>Return to the <a href="machine-learning-for-classification.html#lab8-deliverables"><strong>Deliverables</strong></a> section to check off everything you need to submit for credit in the course management system.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="time-series-image-analysis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["open-geomatics-community-of-practice.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
