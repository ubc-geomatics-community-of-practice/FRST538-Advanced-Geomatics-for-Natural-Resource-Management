[["index.html", "FRST 538: Advanced Geomatics for Natural Resource Management Welcome How to use these resources How to get involved", " FRST 538: Advanced Geomatics for Natural Resource Management Paul D. Pickell 2025-09-01 Welcome These are the course materials for FRST 538 at the University of British Columbia (UBC). These Open Educational Resources (OER) were developed to foster the Geomatics Community of Practice that is hosted by the Faculty of Forestry at UBC. These materials are primarily lab assignments that students enrolled in FRST 538 will complete and submit for credit in the program. Note that much of the data referenced are either public datasets or otherwise only available to students enrolled in the course for credit. Deliverables for these assignments are submitted through the UBC learning management system and only students enrolled in the course may submit these assignments for credit. How to use these resources Each “chapter” is a standalone lab assignment designed to be completed over one or two weeks. Students enrolled in FRST 538 will submit all deliverables through the course management system at UBC for credit and should consult the schedule and deadlines posted there. The casual user can still complete the tutorials step-by-step, but the data that are not already publicly available are not hosted on this website and therefore you will not have access to them. Unless otherwise noted, all materials are Open Educational Resources (OER) and licensed under a Creative Commons license (CC-BY-SA-4.0). Feel free to share and adapt, just be sure to share with the same license and give credit to the author. How to get involved Because this is an open project, we highly encourage contributions from the community. The content is hosted on our GitHub repository and from there you can open an issue or start a discussion. Feel free to open an issue for any typos, factual discrepancies, bugs, or topics you want to see. We are always looking for great Canadian case studies to share! You can also fork our GitHub repository to explore the source code and take the content offline. "],["exploring-spatial-data.html", "Lab: 1 Exploring Spatial Data Lab Overview Learning Objectives Deliverables Data Task 1: Create an ArcGIS Pro Project Task 2: Find your own spatial datasets Task 3: Inspect and Examine your Spatial Data in ArcGIS Pro Task 4: Visualize your Spatial Data in ArcGIS Pro Summary", " Lab: 1 Exploring Spatial Data Written by Paul D. Pickell Lab Overview In this lab you will learn how to find, evaluate, and visualize vector spatial data. You are encouraged to select datasets for a geography that is meaningful to you, such as the area where you are planning to do your project or capstone. This will help you begin to build a library of data that may be directly useful later. As you work through the lab, you will explore some of the basic capabilities of the ArcGIS Pro software that we will continue to build upon throughout the course. You will look at a variety of different spatial data file formats and data types. Y Learning Objectives Locate and download relevant datasets from open data portals Identify spatial data file formats and attribute field data types Inspect metadata (coordinate reference system, extent, file type, data type) within ArcGIS Pro Choose the most appropriate coordinate reference system for your study area Examine attribute tables to understand data content, codes, and field data types Create a simple map that visualizes multiple vector spatial datasets Deliverables Responses to the questions posed throughout the lab on the course management system. (75 points) Upload your final map that shows your three selected datasets. At least one dataset must be symbolized by a field in the attribute table. You can pick the colors/symbols to use for each layer. Layers that appear to use the default random color/weight assignment by ArcGIS Pro will not be accepted for credit. You must show that you manipulated the symbology for each layer. Your map must also contain a title, north arrow, scale bar, and a legend that contains the symbologies of all the layers. (25 points) Data For this lab, you will explore different publicly available spatial data portals. Task 1: Create an ArcGIS Pro Project Step 1: Start ArcGIS Pro. On the start-up screen, you will be prompted to select the type of project. Select “Map” and give your project a meaningful name, something like FRST538_Lab1 is a good choice. When you create a project, ArcGIS Pro will create a folder with your project name in C:\\Users\\[your username]\\Documents\\ArcGIS\\Projects\\[your project name]\\. Inside this folder, you will find ArcGIS Pro has generated a bunch of files and folders. Importantly, there is the .aprx file, which is the file you can use to open your project in ArcGIS Pro. The other important folder is FRST538_Lab1.gdb, which is the default geodatabase for your project. When you start running different tools in ArcGIS Pro, this is where the outputs will automatically be stored. If you navigate to this folder in Windows Explorer, it will just look like a bunch of random files, so you can only view the contents of your geodatabase through GIS software like ArcGIS Pro. Take note of your project location because this is where you will be saving the spatial data files that you download so that you can view them in ArcGIS Pro. In ArcGIS Pro, you should take note of four areas: - The map in the middle; this is where your spatial layers will be mapped, right now you are looking at the default basemap. - The navigation ribbon at the top (Project, Map, Insert, Analysis, View, Edit, Imagery, Share, Help); this is where you can add data and find tools. - The “Contents” pane on the left; this is like a table of contents where your spatial data layers will be listed in the “top-down” that they are drawn/appear on the map. - The “Catalog” pane on the right; this lists sources for data and if you expand “Databases”, you will see your default geodatabase listed there that has the same name as your project. If you do not see the “Contents” and/or “Catalog” panes, then navigate to the “View” tab from the top ribbon, “Set Panes”, then select “Mapping” to return to the default configuration. Step 2: Navigate to the “Map” tab from the top ribbon. This will be the most useful tab for this lab as it allows you to navigate around the map, add data, and select/query the spatial data. The “Navigation” group has methods for panning around and zooming in/out of the the map. If you click “Explore” then you can pan freely around the map. Using your mouse scroll wheel or trackpad scroll gesture on your computer, you can zoom in/out. the other buttons with the arrows allow you to zoom in/out of the centre point of your current map view at fixed intervals. “Bookmarks” allow you to return to the current view of the map after you have navigated away. These can be really handy for returning to the extent/scale that you previously viewed something or maybe for re-locating a feature that you found interesting. If you have a specific coordinate, you can use “Go To XY” to automatically pan to that location. The “Layer” group allows you to change the basemap and add spatial data as layers from various sources. An important concept to understand in GIS is the distinction between “layer” and “data”. “Layers” are exactly that, they are what we see in the map. We can change the colours and symbology of layers in ArcGIS Pro, and these visual choices are stored as part of the .aprx project file. When you add spatial data to your map, they appear as “layers” in the “Contents Pane”. On the other hand, “data” are the spatial data files that are being read from your project folder or some other source. When you change the symbology of a layer, we are not editing or changing the data in any way. Even if remove the layer from your map, you are not deleting the data file, rather you are removing the reference to that file from your project that is used to display the layer. Q1. What are the names of the current layers in your map? (4 points) We will explore the other tool groups in later tasks and other labs. For now, the last feature that you should be aware of is the information toolbar at the very bottom of the application. Here you will find the current scale of your map (1:52,074,088 in the image above), and you can also type any number directly into the box and press Enter to change to a different, set scale. In the middle of the toolbar you can see the location of your cursor with the default units in decimal degrees. On the far right, there is a pause button and a refresh button. These are used to stop loading or re-load the layers in your map. These can be very useful later when it might take your computer a long time to re-draw thousands of features in the layers in your map. In this case, you can pause drawing mode momentarily while you configure the layer symbology. Step 3: From the “Contents” pane, right-click on “Map”, and select “Properties”. Here you can find and set various properties about your map. Navigate to the “Coordinate Systems” from the list on the left and you will see the current Coordinate Reference System (CRS) that is being used by your map. Q2. What is the datum of the current CRS for your map? (2 points) Q3. What is the projection of the current CRS for your map? (2 points) We can change the CRS of the map to any CRS that we want. Notice that there are separate lists for “Geographic Coordinate Systems” and “Projected Coordinate Systems”. Q4. What is the difference between a geographic coordinate system and a projected coordinate system? (10 points) Step 4: Select or search for “North Pole Azimuthal Equidistant” and double-click it or select it and click “Apply”. Inspect the result. We can also modify CRS definitions to create a custom map projection. For example, notice how Canada is rotated in this azimuthal projection because the default central meridian is 0° longitude. Open the map properties again, but this time right-click on “North Pole Azimuthal Equidistant” and select “Copy and Modify”. In the dialogue window that appears, find the value for “Central Meridian” and change it from 0 to -123, then click “Save”, then click “Apply”. Inspect the result. Notice that we have now rotated the map projection over Vancouver, Canada. Feel free to explore other projections, if you want, but before proceeding to the following steps, be sure to change your map CRS back to “WGS 1984 Web Mercator (auxillary sphere)”. What we just explored is that your ArcGIS Pro Map has its own CRS defined. This is an important concept because a map can only have one coordinate system, whether we are talking about a digital map in ArcGIS Pro or an historical paper map. It will be very important for you to understand that your ArcGIS Map can have a different CRS than the data that you want to map. ArcGIS Pro and other modern GIS software solve this issue by re-projecting your spatial data “on-the-fly” using the current CRS of your map. You see the illusion that everything is “mapped” in the same coordinate system, but in fact, your underlying data can be in completely different coordinate systems, even different datums. For our purposes in this lab, this is okay because we will only be visualizing the data as layers, but this issue becomes very problematic when we start to run data through tools and rely on the calculations of position, area, and perimeter/length of features, which can be very inaccurate when working between different CRS. Therefore, it is best practice to choose the CRS that is most appropriate for your study area and purpose and then change your map to that CRS. Q5. What CRS would be most appropriate for your study area and why? Justify your reasoning. (15 points) As you will discover in the next task, spatial data are distributed in a wide variety of coordinate systems, and you are not always guaranteed the CRS that matches your project. So you may need to manually re-project your data before undertaking any analysis beyond simple visualization. Below is a table of three commonly used CRS in British Columbia and Canada: Coordinate Reference System (CRS) Uses NAD 1983 UTM Zone 10N Mapping within Universal Transverse Mercator (UTM) Zone 10 North around Vancouver NAD 1983 BC Environment Albers Mapping across all of British Columbia Canada Albers Equal Area Conic Mapping across all of Canada Task 2: Find your own spatial datasets Spatial data are everywhere. For this task, you will begin to explore different kinds of spatial data portals and also the variety of data formats that you might come across. In later tasks, we will dive further into examining, assessing, and visualizing the datasets that you find. The table below lists a few places to start your search: Portal URL Focus / Notes BC Data Catalogue https://catalogue.data.gov.bc.ca/ Provincial datasets: forestry, land cover, cadastral, climate, transportation, natural resources City of Vancouver Open Data Portal https://opendata.vancouver.ca/ Municipal datasets: zoning, land use, parks, trees, utilities, transportation, planning Government of Canada Geoportal https://geo.ca/home/ Federal datasets: topography, land cover, soils, administrative boundaries Lunaris https://www.lunaris.ca/ National discovery service for research data across Canadian institutions UBC Geospatial Open Data https://github.com/UBCGeodata/ubc-geospatial-opendata UBC-hosted geospatial datasets, campus and research related Natural Resources Canada https://maps.canada.ca/ Federal geospatial data: topographic maps, forests, geology, hydrography Metro Vancouver Data Portal http://www.metrovancouver.org/data Regional planning: air quality, utilities, infrastructure, parks Natural Earth https://www.naturalearthdata.com/ Global vector and raster datasets at multiple scales UN FAO GeoNetwork https://data.apps.fao.org Global agriculture, land cover, and environmental datasets Step 1: Navigate to one or more of the portals linked above and search for three vector datasets that might be relevant to your project. You can select data of any themes that you are interested in, but you must follow these guidelines to receive credit: You must select one dataset each of points, lines, and polygons (i.e., 2D vector data only, and one of each type) You must select datasets from at least two different sources You must only use the sources listed above You must properly cite the source of your dataset Step 2: Once you have found a dataset, download the file into your ArcGIS Pro project folder location that you noted from Task 1. Do not download files directly into your project’s default geodatabase. Most likely the files that you will find will be zipped (compressed), so you will also need to unzip (uncompress) the files into your project folder so that ArcGIS Pro can read them. Pay attention to the metadata on the portal that describe what you are downloading. Metadata are data about data. They describe data and help to make them findable through portals and library indexes. For example, you might come across metadata that describes who the author of the data is, when the data were created/collected/updated, how large the files are and what formats they are, codes for understanding the attribute table, licensing, and more. Rather than provide detailed instructions here for each portal, just ask the instructor or TA if you have any doubts or questions about what you are looking at. Step 3: For each dataset that you download, check the file type and then bring it into ArcGIS Pro using the instructions in the table below. For many file types, you can just drag and drop the file into ArcGIS Pro. You can also navigate to your project folder in the “Catalog” pane (expand “Folders”, expand “FRST538_Lab1”) and drag files from there or right-click files and select “Add To Project” (you may need to right-click the project folder and select “Refresh” to see recently added files from this method). Format File Extension(s) Notes Opening in ArcGIS Pro Shapefile .shp (+ .dbf, .shx, etc.) Legacy, widely used, multiple files Add Data → select .shp GeoPackage .gpkg Modern OGC standard, single file, may contain many layers Add Data → select .gpkg then choose layer File Geodatabase .gdb (folder) ESRI native format, may contain many layers Add Data → browse into folder, select layer GeoJSON .geojson Web-mapping format Add Data → select .geojson FlatGeobuf .fgb Fast modern format Add Data → select .fgb KML/KMZ .kml, .kmz Google Earth Add Data → ArcGIS Pro converts to feature class CSV with coordinates .csv Tabular data with X/Y columns Add Data → XY Table, set fields Step 4: Import you data into your project’s geodatabase. This will vary depending on the file formats that you encounter, but generally you can right-click the geodatabase in the project folder, select “Import”, then select “Feature Class(es)”. In the “Feature Class to Geodatabase” tool that appears, select your three datasets from the drop down menus (if you added them to your ArcGIS Pro Map already) or navigate to the location of the files in your project folder then click “Run”. When it completes, be sure to remove the old layers from your map (right-click the layer, “Remove”) and then add the three feature classes in your geodatabase to your map. Note that ArcGIS Pro refers to vector data (i.e., points, lines, polygons) as a “feature class”. You will see this language throughout various tools in ArcGIS Pro (e.g., “Input Feature Class”, “Output Feature Class”). Up to this point, you have primarily been manipulating data directly through ArcGIS Pro, but you have not really changed much about your actual project. So there is no project state to really save. For example, if ArcGIS Pro crashed right now, you should still be able to find the feature classes that you imported into your project geodatabase. That said, it is good practice to save your project file moving forward as you work through this lab and later assignments. Q6. What are the three datasets you chose and what sources did they come from? Provide the URL to the data source and report the file format that the data were provided in. (15 points) Task 3: Inspect and Examine your Spatial Data in ArcGIS Pro Ensure that you have added your three datasets as layers in your ArcGIS Pro Map. Step 1: Right-click on each layer in the “Contents” pane and select “Properties”. From here, you can view a lot of important metadata for your layers. Navigate to the “Source” tab from the list on the left and then expand “Extent” and “Spatial Reference”. The extent represents the extreme spatial limits of the dataset, as if you drew a rectangle around all the features, what we call a bounding box. In the image above, the units of the extent for the buildings on UBC Vancouver campus are given in decimal degrees (“deg”). Below that, we see the CRS for these data is WGS 1984, a geographic coordinate system. In other words, these data are mapped purely in latitude/longitude values and are not projected. Remember that the CRS of our data can be different than the CRS of our ArcGIS Pro Map. Q7. What is the CRS and extent for each of your three datasets? Paste the values from ArcGIS Pro and be sure to indicate which value cooresponds to which dataset. (15 points) Close the layer properties. Step 2: For each of your layers, right-click the layer in the “Contents” pane and select “Attribute Table”. Inspect the attributes. Are there any acronyms or codes that you are not familiar with? To decode those, you might need to refer to the metadata from the portal. From the top ribbon, click “Table”, then select “Fields”. Here we can see a quick overview of all the data types in the attribute table. Each field must contain values that are in the same data type. Q8. For each of your three datasets, pick one field and report the field name, the data type of the field, and one example of a value stored in that field. (9 points) At the bottom of the attribute table you can quickly see how many features there are. Q9. How many features are in each of your three datasets? (3 points) From the attribute table, you can right-click on any row and select “Zoom To” and the map pan and zoom to that feature in the map. Task 4: Visualize your Spatial Data in ArcGIS Pro In this last task, we will look at some simple ways to manipulate the symbology of your layers and produce and export a final map. Step 1: Right-click one of your layers and select “Symbology”. Note that ArcGIS Pro randomly assigns a colour/symbology to a layer when it is added to the map. Very rarely do data have a pre-defined symbology that come with the data. The default symbology is typically a random colour that is applied to all features, this is called “Single Symbol”. For something like polygons, you can change the fill and the border by clicking the icon next to “Symbol”. From here, you can select any of a number of preset symbologies provided by ArcGIS Pro or you can select the “Properties” tab at the top and customize with whatever features you want. Step 2: From the “Symbology” pane, click the drop-down menu under “Primary Symbology” and select “Graduated Colors”. From here, you can select any numeric field to serve as the basis for applying color to your features. In the example below, I have selected “max_floors” as the field to symbolize and chosen the blue-yellow color palette. ArcGIS Pro will update the layer and also show the classes in the “Contents” pane. Experiment with the different symbology types for your layers and attributes until you arrive at something you like. Be sure to change the smybology of each of your layers. You can also change the basemap to something more neutral like “Light Gray” to make your chosen colour palette more visible (“Map” tab on the top ribbon, select “Basemap”). Step 3: When you are satisfied with your layer symbologies, you can enter the map layout mode to begin the final layout and export process. From the top ribbon, select “Insert”, and then “New Layout”. We are not actually printing the map, so you can select a regular letter size layout in either portrait or landscape mode. This will open a new blank Layout tab in your project and expose a bunch of new options specific to exporting a professional map. Step 4: Add your ArcGIS Pro Map to your Layout by selecting “Map Frame” from the top ribbon under the “Insert” tab. From there, you can select any Maps that you have created in your project. When you select your Map, your cursor will switch to a cross hairs and you just click and drag a rectangle where you want the map to appear on the layout. Step 5: Add a North Arrow, Scale Bar, and Legend from the top ribbon under the “Insert” tab. Pick your favourite styles for these features and experiment with the large number of customization options until you achieve something you like. You can directly rename the layers in your “Contents” pane to update how they appear in the legend. You may need to go back to your individual layer symbologies to adjust how the values are grouped and displayed. Step 6: Add a title to your map by select the text icon in the “Graphics and Text” grouping on the top ribbon under the “Insert” tab. Here you will need to adjust the size and position of the text. Note that there are too many options here to provide detailed instructions for. If you want to know how to do something specifically, just ask your instructor or TA. Map 1. Upload your final map that shows your three selected datasets. At least one dataset must be symbolized by a field in the attribute table. You can pick the colors/symbols to use for each layer. Layers that appear to use the default random color/weight assignment by ArcGIS Pro will not be accepted for credit. You must show that you manipulated the symbology for each layer. Your map must also contain a title, north arrow, scale bar, and a legend that contains the symbologies of all the layers. (25 points) Summary In this lab, you learned how to find, evaluate, and visualize vector spatial data for a study area that matters to you. You searched multiple open data portals, chose relevant vector spatial data, and practiced importing external files into your project geodatabase. You inspected metadata to identify each dataset’s coordinate reference system, extent, and field data types; distinguished geographic vs. projected coordinate systems; and justified an appropriate CRS for your study area. You also examined attribute tables to interpret codes and data types, then customized symbology (single symbol, graduated colors, etc.) so each dataset communicates something meaningful. Finally, you assembled a clean map layout and exported a finished map showing all three datasets. You will likely repeat nearly all of these tasks for almost every GIS project you undertake in the future, and we will continue to build on this foundation in later labs. Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "],["collecting-and-processing-gnss-data.html", "Lab: 2 Collecting and processing GNSS data Lab Overview Task 1: Preparing for GNSS Data Collection Task 2: Collect GNSS Data Task 3: Assess Precision, Accuracy, and Possible Errors Summary", " Lab: 2 Collecting and processing GNSS data Written by Paul D. Pickell Lab Overview Oftentimes, you will need to collect and display your own data. There are many phone applications to collect your own GNSS data. In this lab, you will plan your own GNSS collection, collect data, and process the data. Learning Objectives Plan for field data collection Use AvenzaMaps to collect GNSS readings Evaluate the accuracy and precision of GNSS coordinates Deliverables Responses to the questions posed throughout the lab on the course management system. (57 points) Screenshots of your Trimble GNSS Planning tool charts (your settings must be visible in all the screenshots): Number of Satellites, DOPs, Iono Information, Sky Plot. (8 points) Map of the “True” and “Observed” points. (25 points) Table of accuracy and precision calculated values. (10 points) Task 1: Preparing for GNSS Data Collection Field data collection is an important skill set to learn and practice. In this task, you will plan the collection of your GNSS data in a public park. The task for collecting GNSS data in a public park has nearly the same risks as if you collected the data on campus and you are expected to take similar precautions. This section is meant to inform you of the likely hazards and how to stay safe. Planning Your Data Collection Safety starts at the planning stage. When planning which park you will visit, consider somewhere nearby that is easily accessible by transit or walking. Avoid going somewhere that is unfamiliar to you. Ensure that you are visiting a public park and stay off of private or restricted property. You should only visit the park during daylight hours and plan to go out in sunny weather only. Check government websites for any recent animal sightings before you commit to going to your desired park. Do not plan to collect your GNSS data near bodies of water (e.g., oceans, lakes, ponds, rivers, streams). Do not plan to collect your GNSS data near cliffs or on steep terrain. Finally, ensure that you will have good cell phone coverage in case of an emergency. Likely Hazards At all times, you must be aware of possible hazards both overhead and underfoot. The main overhead hazard in a public park is going to be trees and falling branches. Do not collect your GNSS data during windy or stormy weather, which may cause tree branches to fall. Wet and slippery surfaces, steep angles, holes, logs, debris, and loose soil all pose fall hazards. Many of these hazards can be avoided with careful planning before you even step outside. Speaking of stepping, make sure you wear appropriate footwear, closed toed shoes are best for this work. Fauna are natural inhabitants of parks. Do not visit parks with recent sightings for large, predatory fauna such as bears or cougars. Even urban parks like Stanley Park in downtown Vancouver are known to have coyotes who have attacked people. As well, avoid areas with hazardous flora that may be thorny or poisonous. You may need to cross or transit streets to reach your park. Always follow local traffic laws and look for moving vehicles in and around your park. Always use designated crosswalks and do not look at your phone when walking near stopped or moving vehicles. Do not collect your GNSS data while walking and looking at your phone. Always be aware of your surroundings. Important: If you feel uncomfortable undertaking this task, please contact the instructor for alternative arrangements or accommodations for this particular assignment For this lab, you will decide on your own study area through your own knowledge and simple remote sensing. Your study area must: Be somewhere that you can legally and safely visit Be a park or a greenspace Have at least a portion of its ground visible using aerial imagery (e.g. Google Earth or an ArcGIS Pro basemap) Q1. Describe your study area. Where is it located? What features are around? Why did you choose this location? (5 points) Step 1: Open ArcGIS Pro and turn on an imagery basemap (Map &gt; Basemap &gt; Imagery). Navigate to your proposed study area. You can do this by (a) dragging around your map, (b) putting coordinates into Go To XY, (c) typing in an address or park name into the Locate tool. Before physically visiting your study area, you will need to verify that there are usable reference points in your chosen park. The reference points should be immovable, viewable from the sky and ground, and not tall (not trees or buildings). Additionally, you will be walking to your points – so they should be somewhere safely accessible and not too close or too far from each other. Step 2: Find at least five possible reference points (all at least 10 m from each other). You will create a new feature class and populate it with these reference points. In “Geoprocessing”, find the “Create Feature Class” tool by searching for “Create Feature Class”. Save it to your ArcGIS Pro project geodatabase and give it a meaningful name (for this lab, it will be called “refpoints”). For the other options: Geometry Type: Point Has M: No Has Z: No Coordinate System: –Local UTM– Click “Run” Your new feature class should now be in the “Contents” Pane, but it has no points. Q2. Describe each of your five reference points. What features do they represent? (5 points) Choose “Edit” from the top ribbon, then select “Create”. On the right, a “Create Features” pane will appear. In there, click refpoints, then select “Create a Point Feature”. Zoom in closely on the basemap before creating point features so that the points are more accurate. Click on (at least) four reference points, then select “Save” from the Edit ribbon. If you need to Move a reference point, you can select Move from the Edit Tools. Open the attribute table of refpoints and add three new columns: Name, East, North. Populate the columns for each reference point: Name – a unique name. East – Easting. North – Northing. Easting and Northing can be populated using “Calculate Geometry.” For more relatable measurements in your precision and accuracy assessment (Task 3), use your local UTM for the geometry. Be sure to save your edits. Step 3: You will be exporting a georeferenced map of your study area. Zoom in (or out) to an extent that contains at least the entire park. Using the top ribbon, select Share &gt; Export Map. A pane will pop up on the right-hand side of your screen. The file type is PDF, and make sure that it is saved somewhere you will be able to find it. Toward the bottom of the pane, make sure that the box under “PDF Settings” that says “Export georeference information” is selected. Then select export. This will be used when you are collecting data with Avenza. Step 4: Now that you have established a study area, you need to decide when you will be collecting your data. There are times in the day where you are more likely to get accurate GNSS readings. Find the coordinates of your study area so that you can use them in the Trimble GNSS Planning Online website (http://www.gnssplanning.com/). Go to the Trimble GNSS Planning Online website and enter your study area’s coordinates (one set of coordinates from anywhere within the study area) and elevation. If your coordinates are not in the proper units, either convert them to the proper units. Choose the day that you plan to visit your field site and collect data. After you have input your information into Settings, click “Apply” and look through the other tabs (Satellite Library, Charts, Sky Plot, World View). Using the information on the website, determine the ideal time to collect your GNSS points. Justify your chosen time using the data on the website (this justification should be included on your report, along with screenshots from the webpage). Screenshot 1. Upload a screenshot of the Number of Satellites chart from the Trimble GNSS Planning Tool. The settings that you used must be visible in the screenshot. (2 points) Screenshot 2. Upload a screenshot of the DOPs chart from the Trimble GNSS Planning Tool. The settings that you used must be visible in the screenshot. (2 points) Screenshot 3. Upload a screenshot of the Iono Information chart from the Trimble GNSS Planning Tool. The settings that you used must be visible in the screenshot. (2 points) Screenshot 4. Upload a screenshot of the Sky Plot from the Trimble GNSS Planning Tool. The settings that you used must be visible in the screenshot. (2 points) Q3. Interpret the Trimble GNSS Planning Tool charts and sky plot with 1-2 sentences each. When is the ideal time to collect data at your study area? When did you actually collect data at your study area? (15 points) Task 2: Collect GNSS Data You will need either an Android or iOS smartphone capable of installing the Avenza Maps App. If you do not have an Android or iOS smartphone, then please contact the instructor for alternative arrangements or accommodations Step 1: To start you will need to install Avenza Maps App on your phone. There is an Android version as well as an iOS version so just go to your app store and download it. It’s free! Step 2: Once you have the app installed on your phone, you need to sign up for a free account. If you have concerns about your privacy, you can use a pseudonym and your student UBC e-mail address.Avenza Maps is a widely used mobile mapping application, so chances are you might continue to use it in the future for other projects or hobbies. If you want to ensure future access to your Avenza Maps account and assets, then choose an e-mail account that you will continue to have access to (i.e., not your UBC student e-mail). Step 3: Now that you are registered and logged in, you will change some settings in the Avenza Maps app. Navigate to the Settings in the bottom right corner (for iOS) and in the top right corner (for Android). Scroll down and click “GPS settings”. Use the following settings: Location Source: “Use Only Internal Sources”. This ensures that we are only using the phone’s internal GNSS receiver. Horizontal Accuracy: “Keep all fixes” Distance Thresholds: “Keep all fixes” Time Threshold: “Keep all fixes” Ignore Suspicious Fixes: Toggled Off Next, we will set the units to metric. In Settings, navigate to “Units of Measurement” and select “Metric” at the top. Under “Coordinates”, ensure that the “Format” is set to a workable coordinate system. Step 4: Ensure that the Avenza Maps App is allowed to access your location, camera, and photos in your phone’s settings. Important: Personal location is very sensitive information. You should not undertake this exercise at your home or share the coordinates or screenshots of your home location in Avenza Maps with anyone, including the instructor, TA, or other students in this course. Treat personal location information as any other private sensitive information and handle with respect and care. Step 5: Avenza Maps requires you to load a map before being able to use the location service of your phone. You will import the georeferenced PDF map that you created in Task 1. There are several ways to do this in Avenza Maps, but probably the easiest is to download the PDF to your phone and then import directly from your phone. Be aware that map size can be large and will consume cellular data if you are not connected to a wifi network. If you ran into problems creating your georeferenced PDF, then you can use the provided georeferenced PDF on Canvas for the world. In the end, the actual map that you use is not important for collecting your GNSS data, but Avenza Maps requires a georeferenced map be loaded in the app. Step 6: Travel to your study area! Open the Avenza app, and select the Georeferenced PDF under “My Maps.” Go to one of the reference points you selected in ArcGIS. On the bottom right of the app, there is a button that will bring the map to your current area. Press that button, then press the placemark button directly to the right of it. Create a placemark and name it something meaningful (for example: placemark 1, location 1). Stay exactly where you are, and create a placemark every 10 seconds for the next minute by pressing the location button then the placemark. You should have a total of 6 placemarks. Take a picture of the area you are trying to geographically capture. Go to two more of your designated locations and do the same procedure (create 6 placemarks, each 10 seconds apart, and take a picture. Step 7: Now you can return back to your workstation (after taking a nice walk!). In Avenza, go back to “My Maps,” then select Layers (at the bottom). Select the layer you created, then the icon with three lines at the bottom right. Choose export layers. Export the layer as a KML by pressing the EXPORT option at the top right. A list of export applications should pop up—choose whichever one you would prefer. Step 8: Find your exported file and bring it into ArcGIS Pro. You can drag and drop it from the Catalog Pane into the main map. From there, you should export the kml file to layer using the tool “KML to Layer”. Screenshot 5. Upload an image from one of your reference points. (2 points) Map 1. Upload a map showing the True and Observed points. (25 points) Task 3: Assess Precision, Accuracy, and Possible Errors For this lab, we will consider the initial ArcGIS-created reference points as the “true” values and perform an accuracy assessment with that in mind. Step 1: Visually compare the Avenza-created Placemarks (called “Observed values” for the rest of the lab) with each other and ArcGIS reference points. How close/far are they from one another? You can use the measure tool to add values to this visual assessment. When you are comparing the observed values to each other, you are assessing precision, when you are comparing them to the “True” locations, you are assessing accuracy. Step 2: Quantitatively determine the accuracy of the points. Add two columns in the Observed attribute table and populate them with the east and north values for each point. You should have the True values from your reference point attribute table. Export both tables and bring them into excel. Calculate the horizontal accuracy for each placemark using the following equation: \\(\\sigma_{H_{acc}} = \\sqrt{(\\overline{E} - E_{true})^2 + (\\overline{N} - N_{true})^2}\\) Excel is a convenient place to use this equation. Breaking down the equation – get the mean observed East value, then subtract the “True” East value. Square this difference. Do the same for North. Add the north and east results, then take the square root of them. In excel, you can do this with the equation: =SQRT((average(observed east values)-true east value)^2+((average(observed north values)-true north value)^2)) The resulting value represents how accurate the GNSS measurements were – a lower value represents greater accuracy. Is there a noticeable difference in accuracy between your placemarks? Why do you think this is? To assess the precision, you will use the following equation: \\(\\sigma_{H_{pre} = \\sqrt{\\sigma^2_E + \\sigma^2_N}}\\) Calculate the standard deviation of the observed East and North values, square them, then add them and take the square root of the sum. In excel, you can do this with the equation: =SQRT((STDEV(observed east values)^2 + STDEV(observed values)^2)) The resulting value represents how precise the GNSS measurements were – a lower value represents greater accuracy. Is there a noticeable difference in precision between your placemarks? Why do you think this is? Table 1. Submit a table that shows the accuracy and precision calculated values for each point. (10 points) Q4. Interpret the map and table. (5 points) Q5. Discuss the potential errors in your data collection and describe what may have affected accuracy and precision. Integrate your site observations with the information from the Trimble GNSS Planning tool. Finally, reflect on the validity of the “True” points that you derived from the basemap imagery. (25 points) Summary In this lab, you learned how to plan, collect, and process GNSS data using a combination of ArcGIS Pro, Trimble GNSS Planning tools, and the Avenza Maps mobile application. Planning is a critical part of the GNSS collection process for both safety concerns and also to acquire the best satellite signals. Using the Trimble Planning Tool, you evaluated satellite availability, DOPs, and ionospheric conditions to select an ideal collection time. In the field, you practiced recording GNSS coordinates at reference points with Avenza Maps, producing multiple observations to assess variability. Back in the lab, you compared these “observed” values with the ArcGIS “true” reference points to calculate both precision and accuracy. This exercise highlighted the limitations of phone-based GNSS receivers, the effects of environmental conditions on data quality, and the importance of systematic planning and error assessment in field data collection. Overall, this lab showed you not only the technical workflow for GNSS data collection and analysis but also how to critically evaluate results by integrating field observations with planning tools and quantitative measures of accuracy and precision. Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "],["cartographic-modelling-with-forest-inventories.html", "Lab: 3 Cartographic Modelling with Forest Inventories Lab Overview Learning Objectives Deliverables Data Task 1: Query and export data from UBC PostgreSQL server Task 2: Calculate Percentage of Old Growth Forests References Summary", " Lab: 3 Cartographic Modelling with Forest Inventories Written by Sadie Russell Lab Overview Old growth forests are an important feature found in many types of forested ecosystems. They are characterized not only by their age but also by their complex composition and structure. (LePage &amp; Banner, 2014) Old growth stands boast the highest rates of biodiversity and provide critical habitat for rare, threatened, or endangered species. Additionally, they contribute to soil fertility by supporting intricate soil structures formed by micro-organisms, fungi, and plants. It is generally assumed that the structural complexity desired in a forest develops over time. As such, a stand is designated as old growth once it has reached a certain age without experiencing major disturbance. The length of time required for this designation varies by Biogeoclimatic Ecosystem Classification (BEC) zone. Old growth forests are also highly valued for timber production due to their superior qualities. (Canadian Institute of Forestry, 2022) These trees have had the opportunity to grow slowly over long periods, resulting in denser wood grain and stronger lumber. Furthermore, their tall, straight trunks are ideal for producing a wide range of wood products. To balance the benefits of both logging and preserving old growth forests, frameworks and guidelines are put in place to manage Old Growth sites. In BC, Old Growth Forests are assessed using the Cumulative Effects Framework (CEF). This framework was put in place to provide guidelines on assessing the effects of human activities and natural processes on the provinces forested ecosystems. The province’s old growth and mature-plus-old targets are outlined in the Biodiversity Guidebook (Province of B.C., 1995). Vancouver Island, British Columbia, has been an area of highly contentious Old Growth logging. Conflicting interests between logging companies, First Nations, Provincial and Federal Governments, and the general public came into the spotlight during the Fairy Creek protests of 2020. Over two years of protest, more than 1,000 protesters were arrested at the site (CBC, 2022). The events at Fairy Creek, and many others like it, have brought the issues of Old Growth conservation to the forefront of timber production relations. Learning Objectives By the end of this lab, you will be able to: Prepare and clean a forest inventory dataset and related layers for analysis Perform attribute/select-by-expression filtering to isolate old-growth candidate polygons Calculate old-growth area and percentages by polygon using field calculations Produce a cartographic summary (map + table) that communicates old-growth distribution Reflect on limitations and assumptions of VRI-derived old-growth estimates Deliverables Responses to the questions posed throughout the lab on the course management system. (60 points) A table with fields for total area, old-growth area, and percentage old growth. (10 points) A screenshot of the python expression created for Task 2. (10 points) A map showing the study area and the distribution of difference in calculated old-growth percentage and targets, by polygon. (20 points) Data All data for this lab are accessible via the UBC PostgreSQL server. Instructions for connecting to the server are given in the tasks below. These are very large datasets that come from the BC Data Catalog and are described in the table below. Accessing these data from the UBC PostgreSQL server allows us to extract only the data we need for this lab, which is the extent of Vancouver Island. Layer Name File Name Reference Link Vegetation Resource Inventory 2024 vancouver_island_vri https://catalogue.data.gov.bc.ca/dataset/vri-2024-forest-vegetation-composite-layer-1-l1- Generalized Forest Cover Ownership vancouver_island_own https://catalogue.data.gov.bc.ca/dataset/generalized-forest-cover-ownership Cumulative Effects Framework: Human Disturbance (current) vancouver_island_human_disturbance https://catalogue.data.gov.bc.ca/dataset/bc-cumulative-effects-framework-human-disturbance-current Landscape Units (current) vancouver_island_landscape_units https://catalogue.data.gov.bc.ca/dataset/landscape-units-of-british-columbia-current Task 1: Query and export data from UBC PostgreSQL server Step 1: Ensure that you are authenticated through UBC myVPN. If you are at UBC, use your dedicated ethernet port or connect via the ubcsecure wireless network. If you are away from campus, you will need to first connect to the UBC myVPN service using Cisco AnyConnect Secure Mobility Client. Only authenticated users with a Campus Wide Login (CWL) who are connected to the UBC myVPN may access the UBC PostgreSQL server. However, if you are not a UBC student, then you can just download the data directly from the BC Data Catalogue. Step 2: Start ArcGIS Pro and create a new Map project. Step 3: From the top ribbon, navigate to the “Insert” tab, then click “Connections”, and from the drop-down menu, select “New Database Connection”. You can name it “UBC PostgreSQL Server” and for the host enter “FRST-PostgreSQL.ead.ubc.ca”. The username and password will be provided to students enrolled in the course. Once you have correctly entered the correct credentials, ArcGIS Pro will do a “soft” connection to the server to retrieve the available databases. From the “Database” drop-down menu, select “vri” and then click “OK”. The database connection has now been added to your ArcGIS Pro project, and you can view the tables inside the database from the Catalog Pane (“View” tab &gt; “Catalog Pane” &gt; expand “Databases” &gt; expand “PostgreSQL-FRST-PostgreSQL-vri(student)” &gt; now you can see all the tables in the vri database). You can drag and drop any of the layers of the database directly into your map to visualize them if you want. Though be aware that these are large layers and they may take a while to draw on your map. We do not actually need all of these data, so instead, we are going to use the power of SQL (Structured Query Language) to write a query that will return to us the tiny fraction that we need to use for this lab. First, let us break down what a generic SQL SELECT query looks like: SELECT gid, site_index, species_cd_1, species_pct_1, geom FROM veg_comp_lyr_r1_poly_2024 WHERE bec_zone_code = &#39;CWH&#39;; The SELECT keyword is the most common database operation and the only one that we will use for this lab, but understand that there are keywords for other tasks in the database like creating tables, inserting data, updating data, and deleting data, to name a few. By convention, SQL keywords are capitalized, but most software including ArcGIS Pro do not require this. What follows the SELECT keyword is a comma-separated list of column names that we want to retrieve from the table, gid, site_index, species_cd_1, species_pct_1, geom. You could also replace these with * to return all of the column names and this is generally the default behavior across ArcGIS Pro, so for most tasks in ArcGIS Pro you generally will not need to specify any column names. gid is the primary key of the VRI table, this uniquely identifies all of the polygons from each other. When we select any subset of a table, we always want to grab the primary key because this allows us to keep track of which polygon we are dealing with from the originating table. site_index is the estimate of site productivity for tree growth for the polygon; the values are recorded as decimal numbers. species_cd_1 is the leading tree species code for the polygon; the values are recorded as text strings. species_pct_1 is the percentage of the polygon occupied by the leading species represented by the species_cd_1; the values are recorded as integers. Note that “occupy” here is defined differently, depending on whether the stand is young or mature. geom is the geometry column, which is where the coordinates of the polygons are actually stored. We need this column if we want to map the results of our query. There are 190 other attributes (columns) in the VRI table for each polygon, so this is just a small subset. You should review the VRI Relational Data Dictionary if you have any doubts about what a particular field refers to. Next, the statement describes the table name in the database that these columns are being selected from, FROM veg_comp_lyr_r1_poly_2024. The WHERE bec_zone_code = 'CWH' clause is a conditional statement, which limits the rows (features) returned from the originating table. Note here that we can refer to any column names from the originating table, even if they do not appear in the list of column names that we want to return, as long as they exist in the originating table. Finally, all SQL queries are always concluded with a semicolon ;. You should think of SELECT as subsetting columns of a table (along the x-axis) and WHERE as subsetting rows of a table (along the y-axis). When used together, we are reducing both dimensions of the originating table simultaneously, which substantially reduces the total data that we are retrieving. We will use this principle and expand the SQL statement above in the next step in order to retrieve only the tiny fraction of the VRI data that we need. Step 4: From the top ribbon in ArcGIS Pro, navigate to the “Map” tab, then click the down arrow under “Add Data” and select “Query Layer…” from the drop-down menu. In the “New Query Layer” dialogue window that appears, click the “Datasource” drop-down menu at the top and you should see the UBC PostgreSQL server connection to the vri database listed there that you added at the beginning of this task. It should look something like “PostgreSQL-FRST-PostgreSQL-vri(student).sde”. If not, then click the little database connection button next to the drop-down menu in the dialogue window to add the database connection. (Note: in this specific case, you will need to add the port number to the path string like FRST-PostgreSQL.ead.ubc.ca,5432) We are going to write a select query to retrieve these data from the server, but we do not need all the columns, nor all the rows. We only need polygons that are managed forests and for those polygons, we only need a few attributes that we are going to use later in the lab (“bec_zone_code”, “bec_subzone”, and “proj_age_1”). Step 5: Toggle on “List of Tables” to see the table names and then click on the VRI table in the list “vri.public.vancouver_island_vri” to show the list of columns. (If you get an error message here, then save your project, restart ArcGIS Pro and try again). We are going to write a SQL query to select the polygons that meet some of our initial criteria and then return the values of the columns (attributes) that we will need later. In the “Name” field, name the new query layer “vancouver_island_vri_select”. The VRI data include descriptions about both forested and non-forested lands in British Columbia. Since we are only concerned with forests, we are going to only find polygons that are managed forests. We can do this simply with SELECT * FROM vancouver_island_vri WHERE for_mgmt_land_base_ind = 'Y'. See here that we have not defined any specific column names to return, SELECT * means give me all the columns, so in this example, we are only subsetting on the rows with WHERE for_mgmt_land_base_ind = 'Y', but not the columns. If instead we used SELECT for_mgmt_land_base_ind FROM vancouver_island_vri, then we would get all the polygon values for only the for_mgmt_land_base_ind column name (subset columns, but not rows). You can test this SQL query but do not complete it as a new layer. Q1. What does for_mgmt_land_base_ind select for? What parameters are required to receive a “Yes” value? Hint: take a look at the VRI Relational Data Dictionary. (10 points) Pro tip: When a column value stores a text string, we use single quotation marks in SQL 'abc' around the values that we are searching for, double quotation marks \"abc\" will fail for a SQL query. Step 6: Using what you just learned, draft a select statement that limits the VRI polygons to only managed forests and return only the column names gid, bec_zone_code, bec_subzone, proj_age_1, and geom. Do not run this just yet in ArcGIS Pro, but have it validated by the instructor then press the “Validate” button on the bottom of the dialogue window. If the statement validates successfully, then the “Next” button will allow you to proceed. Pro tip: If you are working from a laptop, be sure to plug into your power source as your computer power options may significantly slow down your ArcGIS Pro performance to conserve battery. Step 7: In the next dialogue, toggle gid as the field that uniquely identifies all features in the table, “Unique Identifier Field(s)” (i.e., the primary key), leave the other fields toggled off. Once you click “Finish”, your select statement will be applied and sent to the server. You will see a small dialogue window that indicates that the extent is being calculated, and this should take about 3-5 minutes before you will see a layer appear in your Table of Contents. Read on to understand the next steps while the server processes your query. Pro tip: It will take another 3-5 minutes before you will see any polygons drawn on your map. You can speed some steps up if you “Pause” the map drawing mode by pressing the pause button at the very bottom of your map. In general, try to keep large layers toggled off so that they are not drawing in the background. Save your ArcGIS Pro project now. Our goal here is not necessarily to visualize the results, though you should see you map automatically pan to Vancouver Island. You can toggle the layer off and visualize it later. If you open the attribute table, you should see the five columns we requested and there should be 275,246 polygons. (Click the “Load All” button at the bottom of the attribute table to verify, which will take some additional time). The query layer that you just created is persistent between ArcGIS Pro sessions if you saved and re-open the project later, but the query layer does not actually contain any data because it just provides the instructions to apply the query to the remote database. It will re-run the query each time you re-open your ArcGIS Pro project, which will take some time to retrieve the data. To avoid this, we are going to actually download the data to our local computer. Step 8: Export the selection you have made your ArcGIS Pro project geodatabase by right-clicking the “vancouver_island_vri_select” layer in your Table of Contents, select “Data”, then select “Export Features”. In the dialogue window that opens, change the output filename to “forest_land_base” (Note: layers stored in geodatabases do not have file extensions), the default location is already the geodatabase for your ArcGIS Pro project. Click “Ok”. This should take about 5 minutes to complete. Next, we are going to export the other layers and download them directly to our ArcGIS Pro project geodatabase. Step 9: From the “Catalog Pane”, export the “vancouver_island_own” layer to your ArcGIS Pro project geodatabase by right-clicking the “vancouver_island_own” layer, select “Export”, then select “Export Features…”. In the dialogue window that opens, change the output filename to “vancouver_island_own” (Note: layers stored in geodatabases do not have file extensions), the default location is already the geodatabase for your ArcGIS Pro project. Click “Ok”. This should take a few minutes to complete. Repeat the last step for “vancouver_island_human_disturbance” and “vancouver_island_landscape_units”. Altogether, this is about 600 MB of data, so be sure you have sufficient disk space and be patient as the data transfer completes. When finished, you can drag the layers into ArcGIS Pro to visualize them on the map. If you paused drawing mode earlier, then unpause it now. The cumulative effects framework only considers forests located on crown land. Next, we will use the forest ownership layer “vancouver_island_own” to select for land ownership types. The ownership_description field describes whether the polygon is private or crown land in a text format. There are lots of different types of crown ownership categories, but for our purpose we need all of them. To do this quickly, we can use LIKE, which is a pattern-matching operator for strings. We need to use the % wildcard to partially-match some pattern. For example, we can search for any row in “vancouver_island_own” with a description of “Crown” using the following statement: SELECT * FROM vancouver_island_own WHERE ownership_description LIKE 'Crown%'. Basically % is a wildcard for zero or more characters, so when we construct the pattern 'Crown%', we are saying match any string that starts with “Crown” and has any number of characters after it. Step 10: Open the attribute table of “vancouver_island_own” by right-clicking the layer in the contents pane. Then click the “Select by Attributes” button then toggle the SQL Editor button to show the SQL codeblock. Write a query to select all the polygons that are crown land. Note that in this particular interface, you only need to give the conditions for selection, so you can omit SELECT * FROM table WHERE. Export the features to your ArcGIS Pro project geodatabase as you did with the the vancouver_island_vri_select, naming the new layer “crown_land” and ensuring that “Use the selected records” is toggled on. CEF human disturbance layer reference methodology document: https://catalogue.data.gov.bc.ca/dataset/7d61ff12-b85f-4aeb-ac8b-7b10e84b046c/resource/7b5789ad-7571-4216-a359-79fd722335f5/download/human-distrubance-description-for-bcdc-archived-and-current.pdf Step 11: Next, we will select the areas where crown land overlaps with potentially forested areas. Use the Pairwise Intersect tool. You can search for it by clicking the toolbox on the top ribbon (“Analysis” tab &gt; “Tools”). Input: forest_land_base, crown_land Output: Crown_Forest Once the tool has finished running, open the new Crown_Forest attribute table to ensure that ‘bec_zone_code’ and ‘bec_subzone’ attributes have been preserved. Step 12: Turn off visibility for other layers in the contents pane on the left side. If the contents pane has been closed, it can be reopened from the ribbon at the top of the screen. Visualize the Crown_Forest layer by BEC_ZONE_CODE or BEC_SUBZONE. To do this, right-click the layer in the contents pane and select ‘Symbology’. Change the primary symbology to ‘Unique Values’ and ‘field 1’ to the attribute of your choice. Pro tip: Polygon outlines can be removed by clicking the symbol of each row in the ‘Classes’ table of the symbology layer. When given the option, select a symbol that does not have an outline. This makes it easier to see the area of many smaller polygons combined. Step 13: In BC forestry standards, the age of a forest stand is categorized by “Seral Stage.” Since the required ages for mature or old growth forests varies depending on the BEC zone, seral stages are used to denote the relative age class of a stand; “Early”, “Mid”, “Mature”, and “Old”. We will create a new field and classify each polygon depending on it’s estimated age. Open the Crown_Forest attribute table and select ‘Add’ in the table ribbon. This will take you to the field view. At the bottom, create a new field using: Name: ‘Seral_Stage’ Data Type: Text To save this new field, click ‘Save’ on the Ribbon at the top of the window. Once it is saved you can close the field view and return to the Crown_Forest attribute table. Once it is saved you can close the field view and return to the Crown_Forest attribute table. Step 14: Right-click the new field and select Calculate Field. The age categories for each seral stage depend on which BEC zone the stand falls within. These age categories correspond with the growth rate and productivity of different eco-zones. The provided code defines the breakdown of Early, Mid, Mature and Old for the three BEC zones found on Vancouver Island. In the expression field paste the following code. This take the BEC zone code and estimated age as inputs into a function that we will define. In the code block under ‘Seral_stage =’, paste: getSeralStage(!BEC_ZONE_CODE!, !PROJ_AGE_1!) In the ‘Code Block’ paste: def getSeralStage(bec, age): if bec == &#39;CWH&#39;: if age &lt;= 40: return &#39;Early&#39; elif age &lt;= 80: return &#39;Mid&#39; elif age &lt;= 250: return &#39;Mature&#39; else: return &#39;Old&#39; elif bec == &#39;MH&#39;: if age &lt;= 40: return &#39;Early&#39; elif age &lt;= 120: return &#39;Mid&#39; elif age &lt;= 250: return &#39;Mature&#39; else: return &#39;Old&#39; elif bec == &#39;CDF&#39;: if age &lt;= 40: return &#39;Early&#39; elif age &lt;= 80: return &#39;Mid&#39; elif age &lt;= 250: return &#39;Mature&#39; else: return &#39;Old&#39; else: return None Note: Ignore the warning message that appears. To better understand what is being done in this code chunk, the syntax is described below. Review that all the rows have been populated in the Seral_stage field. Q2. Define “old growth” and cite at least one primary source. What characteristics might be overlooked by a definition of “old growth” that only accounts for stand age? (10 points) Step 15: Our current layers only depict where crown forests could possibly be. In this step we will remove any areas that have experienced human disturbance in the forms of roads, buildings, and logging. We will use vancouver_island_human_disturbance to do so. Select by attribute where cef_human_disturb_flag is equal to Human Disturb Current 20yr. Export the selected attributes as a new feature named Disturbed_areas. Then, use Select By Location in the top ribbon to identify areas of overlap between potential crown forest stands and areas of disturbance. Input Feature: Crown_Forest Selecting Feature: Disturbed_areas Relationship: Intersect - Leave the rest at default This may take a few moments to run Step 16: In the Crown_Forest attribute table: Click ‘Show Selected Records’ Right-click Seral_Stage field &gt; Calculate Field Expression: \"Early\" Ensure that Use the selected records is toggled on Remove your previous code text if it still remains. Type “Early” (with quotes) into the expression box and leave the Code Block empty. Click Apply Click ‘Clear’ to remove selection Step 17: Old growth forest quantities are assessed in terms of Land Units and BEC Subzones. Land Units are land parcels pre-determined by the BC Government for ease of land management and assessment. We will need to divide our current Crown Forest Landbase by the pre-determined Landscape Units. Open the Pairwise Intersect tool again: Input: Crown_Forest, vancouver_island_landscape_units Output Name: CrownForest_LU Task 2: Calculate Percentage of Old Growth Forests Step 1: Now that we have prepared our layers, we will calculate the percentage of old growth forest within each land unit. To do this we will create a key that uniquely identifies each Landscape Unit + BEC zone + BEC subzone combination. This is a good opportunity to close any unneeded attribute tables or turn off layer visibility. Add a new field to CrownForest_LU attribute table: Add a new field to CrownForest_LU Name: LU_BEC Type: Text In the LU_BEC = textbox, paste: str(!landscape_unit_code!) + &quot;_&quot; + str(bec_zone_c!) + str(!bec_subzone!) The str() function ensures that the attribute values are treated as text strings rather than numeric values for addition. The result should be a new string of landscape unit, BEC zone and subzone. Step 2: We will now calculate the total amount of forested area in each of these landscape unit/BEC zone combination. With the Dissolve tool, we can create new polygons from the landscape identifier: Input Table: CrownForest_LU Dissolve Fields: LU_BEC Statistics Fields: Shape_Area → SUM, BEC_SUBZON → FIRST Output Table: Total_Forest_Area Check “Create Multipart Features” This creates a polygon layer where each feature is one LU_BEC area with total crown forest area as an attribute. Step 3: To identify areas of assumed old growth, we will calculate the area of only forests with “Seral_stage” = old. We can select for old forest by using Select by Attributes on CrownForest_LU before using the Dissolve tool. Ensure that the “use the selected records” option is switched on. Select by Attribute: Seral_Stage = 'Old' Dissolve Fields: LU_BEC Statistics Fields: Shape_Area → SUM Output Table: Old_Forest_Area Ensure Use the selected records is on Check “Create Multipart Features” Now we have created a table of total crown forest area and a table of old growth crown forest area, each by landscape unit. Step 4: We can join these tables back together using a Use Join Field with the following expression: Input Table: Total_Forest_Area Input Field: LU_BEC Join Table: Old_Forest_Area Join Field: LU_BEC Transfer Field: Shape_Area (from Old_Forest_Area) We now have two fields in Total_forest_area named Shape_Area which could lead to some confusion. We can assume that the column with the smaller numbers is the old growth forest area. This should be the last column in the attribute table. Right-click the attribute name to open the field view. Rename the alias of Shape_Area to Total_Area and the alias of Shape_Area_1 to Old_Area. Save your changes. Step 5: Calculate Percent Old Growth Add a new field to Total_Forest_Area: Name: PercentOld Type: Double Use Calculate Field with: Expression: calcPercent(!Shape_Area_1!, !Shape_Area!) Note: the expression still uses the column name rather than the alias. Code Block: def calcPercent(old, total): if old is None or total is None or total == 0: return 0 return (old / total) * 100 Step 6: Classify Percent Compared to Provincial Targets. The target percentages of old growth forests are dependent on the BEC subzone. Instead of assigning each LU–BEC to a discrete class (Low / Intermediate / High), in this step you will create a numeric field representing the difference between the calculated percent old growth and the subzone-specific “high” threshold. You will do this by writing your own python expression to calculate the difference. Refer to the code in step 10 for a guideline on how to build the function. This difference (PercentOld - HighThreshold) is what you will visualize as a continuous gradient: Positive → exceeds the high target, Negative → falls short of the high target, Zero → meets the high target exactly. Begin by adding a new field to Total_Forest_Area: Name: DiffFromHigh Type: Double The percentage thresholds for each class is as follows: Subzone Code Name Low (less than): High (greater than): CDFmm Coastal Douglas-fir 9 13 CWHmm Coastal Western Hemlock Moist Maritime 9 13 CWHvh Coastal Western Hemlock Very Wet Hypermaritime 13 19 CWHvm Coastal Western Hemlock Wet Hypermaritime 13 19 CWHxm Coastal Western Hemlock Very dry maritime 9 13 MHmm Mountain Hemlock Moist Maritime 19 28 Use Calculate Field with: Expression: diff_from_high(!LU_BEC!, !PercentOld!) Now write your own expression to calculate the difference between the old growth target and the calculate old growth percentage. Screenshot 1. Upload a screenshot of your python expression (10 points) Pro Tip: The subzone code can be isolated by removing the first 5 characters with a slice. This would look something like this: bec = lu_bec[5:] We read this as give me all the elements from position 5 to the end of the string, where the colon : separates the “from” and “to” values. If we leave one side of the colon blank, then we are saying we want whatever the minimum (left side of colon) or maximum (right side of colon) number of elements is. Python indexing starts at zero, so if I want to return the letter “g” from the alphabet string abcdefghijklmnopqrstuvwxyz, then I would write something like alphabet[6] or if I want all letters before “g”, then alphabet[:5]. Step 7: Visualize Results In the Contents pane, right-click the Total_Forest_Area layer and select Symbology. In the Symbology panel, set the Field to DiffFromHigh. This will display the data based on the values in that field. Under Primary symbology, choose Graduated Colors (a gradient). Select a color ramp that makes sense for your data. For values that represent low to high differences, use a single-hue light-to-dark ramp (e.g., light yellow → dark green). Avoid using colors that are difficult to interpret (e.g., bright rainbow colors). - Think about your audience—pick colors that clearly show the trend and are readable to someone with color-vision deficiencies.Adjust the classification method and number of classes if needed (e.g., Natural Breaks, Quantile). This determines how your data values are grouped into color ranges. Step 8: Create the Layout Map From the top ribbon, go to the Insert tab and select New Layout. Choose an appropriate page size (e.g., Letter 8.5x11 or A4). Use the Map Frame tool to insert your map view into the layout. Resize and position it so it fills most of the page. - Add essential map elements: - Title: Insert a descriptive map title (e.g., “Difference from High Threshold in Total Forest Area”). North Arrow: Insert → North Arrow. Place it in a corner where it does not overlap important data. Legend: Insert → Legend. This should explain the symbology of your DiffFromHigh values. Scale Bar: Insert → Scale Bar. A useful addition if map distance matters. Author/Date/Text: Add your name and date for documentation. Rearrange and resize elements so the layout looks clean, balanced, and easy to read. Avoid cluttering the map with overlapping items. Step 9: Create the Layout Map When you are satisfied with the layout, go to Share → Export Layout. Choose PNG as the file format. Q3. Describe the results of your final output. What is the distribution of old growth targets met across Vancouver Island? (10 points) Q4. Select 3 other fields in the VRI layer and briefly discuss how they could provide further insight into current old growth status. (10 points) Q5. How is VRI data collected and what limitations does it pose? (10 points) Q6. How might the scale and resolution of GIS data affect the accuracy of old growth assessments? (10 points) Table 1. A table with fields for total area, old-growth area, and percentage old growth. (10 points) Map 1. A map showing the study area and the distribution of difference in calculated old-growth percentage and targets, by polygon. (20 points) References British Columbia &amp; BC Environment (Eds.). (1995). Biodiversity guidebook. Forest Service, British Columbia: BC Environment. Canadian Institute of Forestry (2022). Old Growth Information bulletin. March, 2022 CBC. (2022, February 11). Fairy Creek protesters’ bid to have charges stayed is ‘simply not the way justice is done’: Crown lawyer. CBC News. https://www.cbc.ca/news/canada/british-columbia/protest-court-proceedings-1.6348014 Forest Analysis and Inventory Branch (2024). VRI - 2024 - Forest Vegetation Composite Rank 1 Layer (R1). British Columbia Data Catalogue.https://catalogue.data.gov.bc.ca/dataset/2ebb35d8-c82f-4a17-9c96-612ac3532d55 LePage, P., &amp; Banner, A. (2014). Long-term recovery of forest structure and composition after harvesting in the coastal temperate rainforests of northern British Columbia. Forest Ecology and Management, 318, 250–260. https://doi.org/10.1016/j.foreco.2014.01.031 Ministry of Water, Land and Resource Stewardship (WLRS). (2024). Old Growth Forests in British Columbia: Cumulative Effects Assessment Backgrounder. Victoria, British Columbia. Ministry of Water, Land and Resource Stewardship. 2024. Old Growth Forest Management in British Columbia: Provincial Backgrounder. Victoria, British Columbia. Summary In this lab you standardized VRI layers, filtered the Forest Management Landbase, calculated old-growth areas, and derived percentages to compare across polygons. You then produced a map and exportable table to communicate your findings. The key skills reinforced were: consistent data preparation, careful attribute logic for inventory fields, transparent calculation workflows, and interpreting results within an ecological and management context. Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "],["remote-sensing-image-analysis.html", "Lab: 4 Remote Sensing Imagery Analysis Lab Overview Task 1: The EMS Task 2: Landsat 5 Bands, the EMS &amp; ArcPro Software Task 3: Calculating NDVI and Built Up Index Task 4: Reclassifying Spectral Indices and Map Making Summary", " Lab: 4 Remote Sensing Imagery Analysis Written by Paul D. Pickell Lab Overview The aim of this lab is to learn about the electromagnetic spectrum (EMS), understand spectral properties of different surfaces, and get comfortable using ArcGIS Pro to load and explore different types of remotely sensed images, display individual spectral bands, make different colour composites, and view spectral signatures. In addition, you will calculate two difference spectral indices representing built up areas and green vegetation. Learning Objectives Differentiate regions of the electromagnetic spectrum for urban applications Use Landsat 5 spectral reflectance to map vegetation and urban areas Analyze spectral signatures of different land cover types Deliverables Answers to the questions posed throughout the lab. (31 points) Screenshot of your spectral plot. (2 points) Screenshot of you band arithmetic equation for NDVI. (2 points) Four screenshots of your false-colour composites. (40 points) Map that shows your High_Vegetation_Areas and Urban_area layers overtop the provided Landsat Imagery. Pick appropriate colours and transparency for each layer. (25 points) Data We will be working with a multispectral image of Vancouver from the Landsat 5 satellite (L5047026subset_19990922_7B.dat). Task 1: The EMS The electromagnetic spectrum (EMS) is the distribution of electromagnetic radiation according to wavelength/frequency, and includes radio waves, visible and infrared light, x-rays, gamma rays, and more. In remote sensing, we use the reflective, absorptive, and emissive properties of terrestrial features to identify and measure them (i.e. how do different wavelengths in the EMS interact with the surface of the Earth?). Note: It is important to recognize that the visible part of the EMS is the only section that humans can see. All colours in the visible spectrum are wavelengths, but not all wavelengths in the EMS are colours. Spectral Reflectance Figure 1 shows the reflective characteristics of various features of the earth’s surface. Use this figure to answer Q1 – Q4. Figure 1: Reflectance characteristics of various features at different wavelengths. Q1. For broadleaf and needle-leaf vegetation, what is the approximate wavelength that is reflected most, and what section of the ems does this range belong to? (1 point) Q2. Soil and vegetation reflect roughly the same proportion of blue light. (1 point) Q3. Give a wavelength (in microns) at which snow and ice, dry soil, and vegetation are indistinguishable by their reflectance. In other words, at which wavelength is the proportion of radiation reflected the same (+/- 10%) for these features? (1 point) Q4. Broadleaf and needle leaf vegetation reflect the same amount at 0.7 microns. What causes this? Is there something contained in the foliage of both types of vegetation which causes identical spectral signatures? How does this pattern in spectral reflectance affect how we see live vegetation? (4 points) Figure 2: Reflectance characteristics of unknown features. Q5. Figure 2 contains 4 additional spectra, belonging to unknown surface features. Hypothesize about what these spectra might be and provide your reasoning. Use the known features (broadleaf vegetation, wet soil, etc.) and what you have learned from class/readings to inform your choices. This is a difficult task, and educated guesses are all that is asked for. Do a bit of research, put some thought into it, and explain the reasoning for your guesses. These spectra do not represent the features which are already labeled. You must think of new features which could be observed with remote sensing. (4 points) Task 2: Landsat 5 Bands, the EMS &amp; ArcPro Software Table 2: Parameters of Landsat 5’s Enhanced Thematic Mapper (ETM+) sensor Band Wavelength Range (microns) Spectral Region Spatial Resolution (meters) Applications 1 0.45-0.52 Blue 30 Coastal water mapping, differentiation of vegetation and soils. 2 0.52-0.60 Green 0 Assessment of vegetation vigor. 3 0.63-0.69 Red 30 Chlorophyll absorption for vegetation differentiation. 4 0.76-0.90 Near Infrared 3 Biomass surveys and delineation of water bodies 5 1.55-1.75 Middle Infrared 30 Vegetation and soil moisture measurements. Differentiation of ice and clouds. 6 10.40-12.50 Thermal Infrared 60 Thermal mapping, soil moisture studies, plant heat stress measurement 7 2.08-2.35 Middle Infrared 30 Hydrothermal mapping Q6. Each pixel of landsat’s thermal infrared band (band 6) covers ___ pixels of the other bands. If it helps, draw a picture of the two pixel resolutions. (1 point) Q7. Band 6 is recorded with a coarser resolution because thermal radiation has a very ___ wavelength. Therefore, there is ___ energy available to sense. (1 point) Step 1: Start ArcGIS Pro. To start the lab, Open a new ArcPro map project and open the the L5047026subset_19990922_7B.dat file into the map window. At this point, you should see an RGB satellite image of the city of Vancouver (Figure 3) if the mapview does not immediately pan to the image right click “L5047026subset_19990922_7B.dat” in the Contents pane and press Zoom to Layer. Figure 3: True colour composite of Vancouver. Step 2: Exploring the data It is now time to explore your imagery. Right click the box beside the “L5047026subset_19990922_7B.dat” file in the Contents pane and select “Properties”. Use the menu on the left-hand side and select the Source page and the Raster Information drop down. After clicking on the Raster Information, the tab should open up, and display important information about the image, such as dimensions (number of pixels in the X or Y directions), data types, projection, and resolution (listed as Projection/Pixel). This information can be useful when examining an image! From the “Raster Information” you can see that the spatial resolution of this image is approximately 30 m by 30 m, square. That means that each pixel in the image represents an area of approximately 30 x 30 m on the ground, or 900 square meters. Furthermore, it is a Landsat 5 Thematic Mapper image of Vancouver and its surroundings taken at 22 September 1999 - Wow! Even more details are apparent – its size is 4000 by 3000 pixels, and has seven bands. Scroll down and press on the “Spatial Reference” to see the projection information. We will now use ArcGIS pro to zoom and pan our image. Navigate to the “Map” tab in the top ribbon and hover you mouse of the “Explore” tool: Use these controls to zoom in and out of the image and to pan around, try to zoom into the Fraser estuary and navigate upriver. Included in the Navigate pane there are also the fixed zoom tools the previous extent arrows and the small globe which will zoom to the full extent of your data. Step 3: Displaying Greyscale, True Colour, &amp; False Colour Imagery. Traditionally, single bands of imagery are shown in greyscale, with dark areas shown in black, and light areas shown in white, with anything else shown in shades of grey. Think of each pixel representing a number between 0-255 (byte data type range, the same one of this very imagery!), with areas colored pure black representing the number 0, and areas colored pure white representing the number 255, and everything else is a shade of grey increasing in lightness from 1-254. The figure below displays this concept. Right click on you data in the Contents pane and select “Symbology”. The symbology pane should appear on the side of you window. Press the drop down menu and select “Stretch”. In the next dropdown menu labeled “Band” select “Band 4 NIR” you should see the same image as below. You have now displayed a single band of greyscale imagery. Pixels that are bright/light/white have high amounts of light being reflected back to the sensor in this section of the EMS. Pixels that are dark/black have high amounts of absorption in this section of the EMS. Behind the shades of grey are actual numeric values indicating how much reflected light the sensor detected (from 0-255), that indicate what shade of black/grey/white should be shown. This is a critical component to understand about remote sensing data sets. When more than 1 spectral band is available for a given image (like the Landsat data provided), colours can be used for visualization. Computer monitors display visible light as combinations of red, green, and blue using the RGB colour model. Remember that the colours we see are also a wavelength in the EMS. e.g. Red – 660 nm, Green – 560 nm, Blue – 480 nm In a true colour image, the computer display visualizes objects the way we see them in real life. In other words, in a true colour image, Landsat band 1 (Blue – 480 nm) is displayed as blue, band 2 (Green – 560 nm) is displayed as green, and band 3 (Red – 660 nm) is displayed as red. Any combination where this is not the case is a false color composite, where the colours chosen to visualize the data are not true to life, i.e. Landsat band 1 (Blue – 480 nm) is displayed as red, band 2 (Green – 560 nm) is displayed as blue, and band 3 (Red – 660 nm) is displayed as green. Visualizing wavelengths outside of the visible spectrum (Landsat bands 4-7) automatically apply as false colour composites. False colour composites are necessary because many remote sensing devices can measure a broader range of wavelengths than humans can see. As a result, in order to display these data visually for humans, they must be displayed using a part of the spectrum that humans can see (Red, Green, Blue). In the Symbology pane navigate back to “RGB” in the first dropdown list. Your image should change back into a True Colour Landsat image where band3 red is visualised as red, band 2 green is visualised as green and band1 blue is visualised as blue. By displaying false colour composites it is possible to display many band combinations of the image on our screen. This time you will create a false colour composite by selecting different wavelengths (bands) to be visualized using red, green and blue colours. In the Symbology pane under their respective drop done lists visualize the following band combination. Band 4 using Red Band 2 using Green Band 7 using Blue You should see the following: You can experiment with different band combinations by visualizing different bands using Red, Green and Blue. A standard false colour composite, for instance, has Band 4 visualized using Red, Band 3 visualized using Green and Band 2 visualized using Blue, as shown below: Right click the bands in the Contents pane, turn different layers on and off by clicking the check mark off and on in the IsVisible section. Zoom and pan around and investigate different areas of Vancouver that you may know. Feel free to use google maps or google earth to help you orient yourself. Q8. In a false color composite where near landsat band 5 is mapped to the red color channel, band 4 is mapped to the green color channel, and band 3 is mapped to the blue color channel, match the following cover types to the colors that they appear in the image: healthy vegetation, urban cover, silty water, and clear water. (4 points) Q9. Experiment with many different false colour composites. Which 3 bands would you combine if you wanted to analyze vegetation? Do some light research on spectral properties and the applications of different landsat bands and write a sentence or two justifying each of your choices. Then, append a screenshot of your chosen composite to your response. (10 points) Q10. Experiment with many different false colour composites. Which 3 bands would you combine if you wanted to analyze water quality? Do some light research on spectral properties and the applications of different landsat bands and write a sentence or two justifying each of your choices. Then, append a screenshot of your chosen composite to your response. (10 points) Q11. Experiment with many different false colour composites. Which 3 bands would you combine if you wanted to analyze agriculture? Do some light research on spectral properties and the applications of different landsat bands and write a sentence or two justifying each of your choices. Then, append a screenshot of your chosen composite to your response. (10 points) Q12. Experiment with many different false colour composites. Which 3 bands would you combine if you wanted to analyze urban areas? Do some light research on spectral properties and the applications of different landsat bands and write a sentence or two justifying each of your choices. Then, append a screenshot of your chosen composite to your response. (10 points) Step 4: Viewing Spectral Signatures Now it is time to examine your data set more thoroughly. At the beginning of this lecture we examined the spectral signatures of different materials. We will now do the same thing for the different sections of our Vancouver Landsat image. Right click on the “L5047026subset_19990922_7B.dat” file in the Contents pane and select Create Chart -&gt; Spectral Profile. The Chart Properties pane should appear on the right side of your screen and the spectral chart on the bottom. In the Chart properties pane under “Define an Area of Interest” select “point” and then click a pixel on your map. Change the colour and select a variety of different points representing different land cover types (Urban, forest, water, crops, snow). You might have to resize the spectral chart at the bottom of your screen in order to see the different profiles. Your chart should look something like this. Q13. Examine your new spectral profile chart, compare the different profiles you created to the spectral profiles in figures 1 and 2. What is different between them? Why might your spectral curves look different than the ones above? (4 points) Screenshot 1. Upload a screenshot of your spectral plot. (2 points) Task 3: Calculating NDVI and Built Up Index Spectral indices are mathematical equations containing spectral reflectance values from two or more wavelengths used to highlight areas of spectral importance in an image. There are a wide variety of spectral indices used to highlight a variety of different land covers and image properties including burned Areas (Normalized Burn Ratio), urban/ built up areas (Normalized Difference Built-Up Index), and water (Normalized Difference Water Index) to name a few. The Normalized Difference Vegetation Index (NDVI) is a frequently used spectral index that takes advantage of the high near-infrared reflectance and high red absorption properties of healthy vegetation and is therefore often used to quantify vegetation in a remotely sensed multispectral image. NDVI is calculated with the below formula: \\(\\ NDVI = \\frac{(NIR - RED)}{(NIR+RED)}\\) Where NIR is the near-infrared band (Landsat 5 Band 4) and Red is the red band (Landsat 5 Band 3). The results of this equation should be between -1 and 1 with values less than 0 representing water and values between 0-1 representing different levels of green vegetation. While ArcGIS Pro contains a built-in tool to calculate NDVI and a series of other spectral indices, in this lab we will be using the “band arithmetic” function and the above equation to create our own NDVI tool. Navigate to the Imagery ribbon at the top of your ArcPro window and click the “Raster Function” button. The Raster Functions pane should appear, you can either navigate the drop down menus to “Math”, “Band Arithmetic” or use the search function to find the “Band Arithmetic Tool” and click to open. The “Band Arithmetic Properties” dialogue should appear. Under “Raster” use the drop down menu and select the “L5047026subset_19990922_7B.dat” layer. If it is not currently in your map view and can use the folder button and navigate to your lab data folder and select the file. Under “Method” select “User Defined”. It should look like the screen shot below. Use your knowledge of spectral indices, the NDVI formula given above and the table below fill in the NDVI calculation for your data. Screenshot 2. Upload a screenshot of you band arithmetic equation for NDVI. (2 points) Q14. What are the minimum and maximum values of your new NDVI layer? (2 points) Q15. What do the dark areas in the image represent? The gray areas? The white? (4 points) Q16. What information does this type of analysis give us? When and why might this type of analysis be used? (4 points) We will now use the “Band Arithmetic” window to calculate the Normalized Difference Built-Up Index (NDBI). The NDBI highlights urban areas where there is typically a higher reflectance in the shortwave-infrared region compared to the near-infrared region. The equation is as follows: \\(\\ NDBI = \\frac{(SWIR-NIR)}{(SWIR+NIR)}\\) Open the “Band Arithmetic” function and select the Landsat scene as your input raster. Under “Method” use the drop-down menu and navigate to NDBI. Using what you know about Landsat imagery select the proper bands for calculating NDBI under the “Band Indexes” box and then select “Create New Layer”. Task 4: Reclassifying Spectral Indices and Map Making In the section you will use a technique called Thresholding and the reclassify tool to extract highly vegetated areas (High NDVI) and urban areas (High NDBI) and then create a map with these layers overlaid with the provided satellite imagery. Under the “Analysis” ribbon select the “Tools” option. The geoprocessing window should appear in the search box type “Reclassify” and select the option with (Spatial Analyst Tools) beside it. Under “Input Raster” select the NDVI layer you created earlier. The “Reclass field” should automatically become completed and a “Reclassification” table should appear below. Select the Classify button at the bottom of the table and enter “2” for number of classes. For the first row leave “Start” as is and enter 0.49999 under “End”, change “New” to “NODATA”. For the second row change “Start” to “0.5” and leave “End” as 1 and change “New” to “1”. The Reclassify tool takes the old values from a raster and creates a new raster layer with updated values based on the Reclassification table. In this case we as saying take all pixels with values less than 0.5 and make them NODATA or blank and take all pixels with values greater than 0.5 and make their value 1. Under “Output Raster” save the file as “High_Vegetation_Areas” and press “Run” at the bottom of the window. Now use the Reclassify tool to create a new layer from the NDBI where all you keep only pixels with values above 0 and change there value to 1. Save this layer as “Urban Areas”. 4.0.0.0.1 Map 1. Upload a map that shows your High_Vegetation_Areas and Urban_area layers overtop of the provided Landsat Imagery. Pick appropriate colours and transparency for each layer. (25 points) Summary In this lab, you learned how to interpret the electromagnetic spectrum for urban and environmental applications, connect spectral behavior to what you see in imagery, and operationalize those ideas in ArcGIS Pro. You explored Landsat 5 bands, toggled single-band greyscale views, and built both true- and false-colour composites to emphasize specific surface properties. You examined spectral signatures for different land covers and compared them to reference curves to understand why materials separate (or don’t) across wavelengths. You then calculated NDVI to highlight vegetation and NDBI to highlight built-up areas, and reclassified these indices to extract high-confidence classes. Finally, you synthesized your results into a clear map that overlays vegetation and urban masks on the base imagery. By the end, you could differentiate EMS regions, justify band choices for specific analyses, quantify patterns with indices, and communicate findings cartographically. Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "],["lidar-forest-management.html", "Lab: 5 LiDAR for Forest Management Lab Overview Task 1: Load and understand LiDAR data in a Map Project Task 2: Create a DEM, DSM and CHM Task 3: Mapping Tree Tops Task 4: Visualization in 3D Summary", " Lab: 5 LiDAR for Forest Management Written by Hana Travers-Smith Lab Overview LiDAR, short for Light Detection and Ranging, is a remote sensing technology that uses laser pulses to measure distances and create detailed 3D maps of objects and environments. To map vegetation, LiDAR emits laser beams from an aircraft or ground-based system towards the vegetation canopy. The laser pulses bounce back upon hitting objects, including leaves, branches, and the ground. By measuring the time it takes for the pulses to return, LiDAR calculates the distance to each point, generating a “point cloud” of data. “Point clouds” can be used to create high-resolution maps depicting the vertical structure of vegetation, including tree heights, density, and ground cover. These maps are invaluable for understanding ecosystem health, biodiversity, carbon storage, and assisting in land management decisions such as forest monitoring, conservation planning, and urban development. In this lab you will use high resolution LiDAR data collected by the City of Vancouver to create a model of terrain and vegetation for a forest located on UBC campus. Learning Objectives Understand how LiDAR data is collected Learn how to model terrain and vegetation from a LiDAR point cloud Visualize 3D data in a Scene Deliverables Answers to the questions posed throughout the lab. (60 points) Screenshot of your Canopy Height Model (CHM). (15 points) Screenshot of final 3D ArcGIS Pro Scene. (15 points) Data Lidar data collected by the City of Vancouver in .las format Task 1: Load and understand LiDAR data in a Map Project Step 1: Download the LiDAR data from the following link: https://opendata.vancouver.ca/explore/dataset/lidar-2018/information/ THe data is split up into a tiled grid system. You will download one tile covering a section of UBC. Use the “Table” view and search for the following tile and download it: “4840E_54550N” by clicking on the .zip link. Use the metadata from the City of Vancouver data portal to answer the following questions: Q1. What is the horizontal and vertical datum of the LAS dataset? Why is it important for Lidar data to have both horiziantal AND vertical datums? (10 points) Q2. What is the point density of the dataset (points per m2)? (4 points) Step 2: Create a new project in ArcGIS Pro. ArcGIS Pro has several tools that we can use to view and analyse LiDAR point clouds. In order to view the dataset, we need to import it as a LAS Dataset. From the geoprcessing pane, search for the “Create LAS dataset” tool, then parameterize it as follows: Input File: 4840E_54550N.las Output LAS Dataset: LAS Dataset.lasd Coodinate System: Use the horizontal datum from the dataset specifications Create PRJ for LAS Files: All LAS files Check the “Compute Statistics’ box. Surface Constraints can be left blank Step 3: Depending on the zoom extent, you may only see the red bounding box of the las file; this isn”t an error, you just need to zoom in to see the actual points. The points can be classified into the following categories: Ground Non-Ground 1st Return (highest feature) The default display is that no point cloud filters are applied. To quickly filter only ground points right click on the file in the Contents Pane, navigate to “LAS Filters”, and click “Ground”. There is also a more detailed classification system, which includes vegetation, water, noise, buildings etc. Right-click on the the file &gt; Properties &gt; LAS Filter. This menu gives you more control for which points you want to display from the dataset. Task 2: Create a DEM, DSM and CHM In this task we will create 3 raster datasets by interpolating heights from the point cloud to create continuous surfaces: Digitial Elevation Model (DEM) - sometimes referred to as a Digitial Terrain Model (DTM) Digital Surface Model (DSM) Canopy Height Model (CHM) Q3. What does a DEM, DSM and CHM represent? How do you interpret the values in each one? (15 points) Step 1: First, we will create a DEM from the .lasd point cloud. Filter the point cloud so that only points labelled ‘02 Ground’ are displayed. Analysis &gt; Tools &gt; Search for “LAS Dataset to Raster”. We will use the “Binning” method to interpolate elevation. This method works by dividing the point cloud into cells (pixels) and assigning a value to each cell based on the heights of all the points in the cell. For example, cell values could be assigned as the average height of all points within a 10x10m pixel. Input LAS Dataset: LAS Dataset.lasd Output Raster: DEM Value Field: Elevation Interpolation Type: Binning Cell Assignment: Average Void Fill Method: Linear Output Data Type: Floating Point Sampling Type: Cell size Sampling Value: 10 (this defines the resolution of the output raster as 10m) Z factor: 1 Q4. What is the minimum value of the DEM? (2 points) Q5. What is the maximum value of the DEM? (2 points) You should now have something that looks like this: Step 2: Next, we will create a DSM. We need to ensure that all point labelled as ‘Noise’ are filtered out from the dataset, we will also filter out ‘Ground’ points and just retain points coming from vegetation/infrastructure. Navigate to the LAS Filter menu in the data Properties tab. Uncheck the following codes: 0 Never Classified 1 Unassigned 2 Ground 7 Noise Once you have correctly filtered the point cloud open the “LAS Dataset to Raster” tool. This time we will use the “Maximum” value as the Cell Assignment. Name the output raster “DSM”. All other settings can stay the same as the DEM. &gt; Run Q6. Why might we want to use the Maximum value as the Cell Assignment method for a DSM? (5 points) Q7. What features or land cover types can you idenify from the DSM? (5 points) Step 3: Finally, we will create a CHM using the DEM and DSM. Navigate to Analysis &gt; Tools &gt; Raster Calculator (Image Analyst Tools).This tool allows you to create a new raster by combining multiple rasters using simple mathematical operators (adding, subtracting etc). Calculate the CHM as: DSM - DEM Q8. Explain why we need to subtract the DEM from the DSM to calculate canopy height. Describe potential sources of error in deriving a CHM from this method. (10 points) Screenshot 1: Upload a screenshot of your final CHM. Change the default symbology to show unvegetated areas, medium vegetation &lt;30m and tall vegetation &gt;30m. (15 points) Task 3: Mapping Tree Tops Using what you learned in the last task, now you will create a point shapefile of treetops using a higher resolution canopy height model. Step 1: First, we will derive a DSM using points representing High Vegetation. Open the LAS Filter menu and make sure only points labelled “5 High Vegetation” are checked. Next, use the “LAS Dataset to Raster” tool to create a raster from the filtered point cloud with the following properties: 1m spatial resolution the raster values should represent the highest point in each cell name the output “DSM_1m” Step 2: Next, produce a DEM “DEM_1m” at the same spatial resolution of 1m using what you learned in the last task. Step 3: Again following what you learned in the last task, subtract the 1m DEM from the 1m DSM and name the output file TreeTops. Q9. What features are now visible in the 1m DSM that were not visible in the 10m DSM? (5 points) Step 4: Next we will use the “Focal Statistics” tool to identify the maximum height of tree crowns across the forest. We will use a Circular Neighborhood with a Radius of 5. This will calculate the maximum elevation observed within a 11m circular moving window (5m is the radius, 10m is the diameter, plus one more cell for the focal cell = 11m). Use the following parameters: Input raster: TreeTops Output raster: TreeTop_max Neighbourhood: Circle Radius: 5 Unit type: Cell Statistic Type: Maximum Ignore no data in calculations: Checked Q10. What is a moving window? If you are using a focal maximum, explain how cell values assigned in the final output. (5 points) Step 3: Open the “Raster Calculator” tool. We will use this tool to find the pixels in the “TreeTops” raster that match the maximum focal height in the “TreeTops_max”. To do this, we will use a True/False conditional statement using the Con syntax: Con(statement, iftrue, if false) - Essentially for each pixel the statement is evaulated and if it is true an action is taken, and if it is false a different action is taken. Enter the following statement in the “Raster Calculator” tool: Con(\"TreeTops\"==\"TreeTops_max\", \"TreeTops_max\") Basically, this is a calculation that evaluates the statement “where is the”TreeTops” raster equal to the maximum elevation value identified from the focal statistics?” Where these pixels match, write the maximum value to the output. Otherwise, write a value of NoData to the output. Save the output as “tree_with_height”. Refer to the screenshot below for writing this statement correctly. Inspect the output. Zooming in reveals what we have done. Pixels that represent the maximum height in each focal window are assigned a value equal to the maximum height, while all other pixels have a NoData value. Step 4: Open the “Raster to Point” tool. The input raster is the raster that you just made. Field is Value, and the output name should be “tree_with_height”. Input: tree_with_height Field: Value Output: Final_treetops Q11. How many tree tops are in the final output? (2 points) Task 4: Visualization in 3D So far we have worked with the point cloud data in flat, 2-dimensional space. In this task, you will explore the point cloud in 3-dimensions in a Scene. On the top ribbon “Insert” &gt; “New Map” &gt; “New Local Scene”. Step 1: Practice using the On Screen Navigator to manipulate the scene. The first toggle let’s you navigate in the normal directions and the second toggle (the person) let’s you rotate the scene in 3D. Step 2: Navigate to the UBC campus study area and change the Basemap to “Imagery” in the Map tab located on the top ribbon. In the Contents pane, right-click Ground, located below the Elevation Surfaces group layer. Click “Add Elevation Source”. Browse to the location of your 10m DSM and select it. You can now start to see how the surface features have been incorporated into the surface. Make sure to zoom in to look at areas with high relief and roads. Add the “TreeTops_Final” point shapefile to the Scene. Step 3: Click on “Ground” underneath the Elevation Surfaces tab. On the top ribbon click ’Elevation Surface Layer. Set the Vertical Exaggeration to 2 - this will increase the contrast between high/low elevation in the scene. Finally, turn off the WorldElevation3D/Terrain3d layer to better see how the DSM. Screenshot 2: Upload a screenshot of the final Scene. Add the tree tops points to the visualization. (See example below, note that yours will also include the tree tops points). (15 points) Q12. Experiment with the 10m and 1m DSM. How does the DSM resolution impact the 3D visualization? Which visualization is more realistic? (5 points) Summary In this lab, you learned how LiDAR data is collected, structured, and used to model forested landscapes. You explored raw point cloud data in ArcGIS Pro, applied filters to distinguish between ground, vegetation, and other surface features, and generated continuous surfaces including a Digital Elevation Model (DEM), a Digital Surface Model (DSM), and a Canopy Height Model (CHM). By comparing these layers, you practiced interpreting terrain, vegetation structure, and potential sources of error in canopy height estimation. You then worked at a finer resolution to map tree tops by applying focal statistics and raster-to-point conversion, creating a dataset of individual tree crown positions and heights. Finally, you visualized the forest in 3D using ArcGIS Pro”s Scene tools, experimenting with different resolutions to see how they influence realism and detail. Through these steps, you developed practical skills in working with LiDAR point clouds, learned how to transform raw 3D data into meaningful forest management layers, and gained an understanding of how spatial resolution impacts ecological interpretation. Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "],["terrain-and-riparian-area-management.html", "Lab: 6 Terrain Analysis and Riparian Area Management Lab Overview Learning Objectives Lab Background Deliverables Data Task 1: Prepare the DEM and Map Stream Networks Task 2: Extract Stream Characteristics Task 3: Mapping Watersheds and Riparian Management Areas Summary", " Lab: 6 Terrain Analysis and Riparian Area Management Written by Hana Travers-Smith Lab Overview In this lab you will take on the role of a forest manager with the following task: Define reserve (no harvest) areas within a topographically complex riparian forest using current “best management” practices. To do this you will use a Digital Elevation Model and high-resolution basemaps. The deliverable for this assignment will be a written report where you will assess the application of DEMs for forest management in riparian regions. Learning Objectives Practice characterizing riparian areas using hydrologic toolsets Execute tasks using Python scripting Evaluate harvestable areas near riparian management areas Lab Background Riparian areas are found adjacent streams, lakes and wetlands. In many areas they contain highly productive and commercially valuable timber. However, vegetation in riparian zones also has important ecological function by stabilizing stream banks, regulating water temperature, providing nutrient inputs and reducing runoff into water bodies. In British Columbia, Riparian Management Areas (RMAs) are defined around sensitive streams and rivers that forbid or limit forest harvest activities within them. The width of these buffer zones depend on stream class, which is defined by channel width and fish-bearing potential. Thus, it is critical for forest managers to accurately map and measure stream networks. Airborne Laser Scanning (ALS) can be used to derive detailed maps of terrain and vegetation structure to aid in riparian forest management. Previous work has been done using ALS to map and extract stream characteristics over large areas and assign stream classes (Tompalski et al., 2017). You will use similar methods to classify streams and define RMAs over a small area in the Nahmint valley, British Columbia. Throughout this lab stream order refers to the Strahler or Shreve ordering system seen in your previous lab, and stream class refers to the BC government stream classification used to determine riparian management areas. More background information on riparian forest management in British Columbia can be found here: https://www2.gov.bc.ca/gov/content/industry/forestry/managing-our-forest-resources/silviculture/silvicultural-systems/silviculture-guidebooks/riparian-management-area-guidebook Deliverables Answers to the questions posed throughout the lab. (75 points) Map that shows the stream network polylines (symbolized by stream class), watersheds, contours, an inset map showing example stream network and Riparian Management Areas, and text showing the total area in the Reserve and Management Zone and the length of the stream network. (25 points) Data The data for this lab are a Digital Elevation Model (DEM) of the Nahmint watershed region in British Columbia available from the course management system. Task 1: Prepare the DEM and Map Stream Networks Step 1: Open a new ArcGIS Pro project and import the “Nahmint_DEM.tif”. We will do a few pre-processing steps before generating a stream network. Use the “Fill” tool to remove any sinks from the DEM. Sinks are small imperfections in the DEM that create areas where water cannot flow out of. If sinks are not eliminated, water flow can get trapped within these depressions, leading to unrealistic pooling of water and incorrect delineation of watershed boundaries. From the geoprocessing pane, search for the “Fill (Spatial Analyst)” tool. Input Surface Raster: Nahmint_DEM Output Surface Raster: Nahmint_fill Z limit: leave blank The Z-limit represents the minimum depth of sinks that will be filled. For example, if it is set to 10 m then only sinks deeper than 10 m will be filled. For now leave this field blank, this will fill all sinks in the data. Step 2: Use the “Flow Direction” tool to to calculate the direction of water flow across the landscape. Use the following parameters for the tool: Input surface raster: Nahmint_fill Output flow direction raster: Nahmint_FlowDir Flow Direction Type: D8 Leave the rest blank/unchecked There are three flow modelling algorithms, but we will use the simplest: D8. In this model water will flow from one cell to its steepest downslope neighbour. The cell will then be assigned a value based on which of its 8 neighbours water will flow into. Click Run. You should now have something like the image below: Figure 6.1: Flow Direction. What direction is water flowing at points A and B? You will need to interpret this raster in your Results and Discussion. Use the ArcGIS Pro documentation to understand the output if necessary. Step 3: We will use the flow direction raster calculated in the last step to calculate flow accumulation, which counts the total number of cells that will flow into a given cell. For example, a cell located at the bottom of the hill will have high flow accumulation and a cell at the top of a hill will not have any flow accumulation. Open the “Flow Accumulation” tool and parameterize it as follows: Input flow direction raster: Nahmint_FlowDir Output flow accumulation raster: FlowAcc Output data type: Integer Input flow direction type: D8 Leave all other fields blank then run the tool. Step 4: Next, we will create a raster-based stream network using a threshold in the flow accumulation raster. For example, if the threshold is 100, then only cells with flow accumulation greater than 100 will be counted as a stream. Cells with flow accumulation less than 100 will be set to a background value of 0. To see how different thresholds impact stream identification, change the symbology of the flow accumulation raster and use the “Manual Interval” symbology to set two classes. See the example below for a stream network with a flow accumulation threshold of 100 (cells with flow accumulation &lt; 100 are set to no color). Note that in the example below the threshold is likely too small, and results in many small streams that are not evident in the ArcGIS basemap. Q1. What flow accumulation threshold value did you use to create Stream_reclass? (4 points) Compare your stream network to the streams visible in the ArcGIS satellite basemap and the filled DEM (use the shaded relief symbology for a better visualization). Experiment with different flow accumulation thresholds. What other features could be misclassified as a stream using this method? Find a threshold that captures a realisitc stream network visible in the basemap and DEM, without too many misclassified features. Once you have selected a threshold, open the “Reclassify (Spatial Analyst Tools)” tool. Use the threshold you have selected as the Start and End values. Set the cells representing streams to a “New value” of 1 and all other cells to NODATA. Save the new raster as “Stream_reclass”. Zoom into the reclassified flow accumulation raster to see your stream network. Step 5: Next, we will assign a stream order to each segment in the stream network. Stream ordering is a system to classify streams based on the number of tributaries (smaller streams) that flow into it. First order streams have no tributaries and higher order streams may have multiple levels of tributaries flowing into it. Open the “Stream Order” tool and parameterize it as follows: Input stream raster: Stream_reclass Input flow direction raster: Nahmint_FlowDir Method of stream ordering: Strahler Output raster: StreamOrder Zoom in to see the “StreamOrder” output. The value of each pixel corresponds to the order of each stream segment. Now re-run the tool using the Shreve method and compare the two outputs (You will compare these two outputs in the Discussion section of your report). Q2. Compare and contrast the Strahler and Shreve methods for stream ordering. (5 points) Step 6: Use the “Stream to Feature (Spatial Analyst Tools)” tool to create polyline features representing the ordered stream network. Parameterize the tool as follows: Input stream raster: StreamOrder Input flow direction raster: Nahmint_FlowDir Output polyline features: StreamNetwork_polyline Simplify polylines: Checked Open the polyline attribute table. The “grid_code” field corresponds to the stream order of the segment. The tool also generates attributes describing the start and end points of each segment and the segment length. Step 7: Finally, we will assign a unique numeric ID to each stream segment using the “Stream Link” tool. Parameterize the tool as follows: Input stream raster: Stream_reclass Input flow direction raster: Nahmint_FlowDir Output raster: StreamLinks Zoom in and examine the output. Q3. Interpret the accuracy of stream networks compared to basemaps. Discuss potential sources of error and how they could be improved. (5 points) Task 2: Extract Stream Characteristics In this task we will calculate stream gradient and estimate width for each segment in the network. These metrics will be used to assign a stream class and define the width of the riparian management area. Percent gradient is a measure of the streams “steepness” and is calculated as: \\[ \\frac{EC}{SL}*100 \\] \\(EC\\) is elevation change \\(SL\\) is stream length Streams with a gradient &lt;20% are considered “fish bearing” in the absence of other field data. Step 1: First, use the “Raster Calculator” tool to multiply the classified flow accumulation layer “Stream_reclass” and the “Nahmint_DEM” layer. This will give elevation within streams. Name the output “streams_elevation”. Step 2: Open the “Zonal Statistics” tool. This tool calculates summary statistics in one raster layer within “zones” or groups defined in another layer. This is a very useful tool for many applications! We will use the unique IDs from the “StreamLinks” layer as “zones” to calculate the change in elevation within each stream segment. The resulting raster shows the gain in elevation within each stream segment. Step 3: We will convert the elevation change raster to polygon using the “Raster to Polygon” tool. (You may have to first convert the raster from floating point to integer format using the Int Tool). Save the output of “Raster to Polygon” as “elevation_change_polygon” and check “Simplify Polygons”. This step will allow us to perform a spatial join with the vectorized stream network. Open the attribute table and note that some attribute names are the same as the “StreamNetwork_polyline”. The attribute “grid_code” represents the elevation gain within each stream segment. You can change the field names in both layers so you don’t get confused after joining the two features. Step 4: Open the “Spatial Join” tool and join “StreamNetwork_polyline” with the “gradient_polygon”. Parameterize the tool as follows: Target Features: StreamNetwork_polyline Join Features: elevation_change_polygon Output Feature Class: StreamNetwork_join Join operation: Join one to one Keep all target features: Checked Match Option: Largest Overlap Search Radius: 3 Meters Step 5: Open the attribute table of the “StreamNetwork_join” feature class. If you have duplicated attribute names, the attributes are ordered first with the Target Feature and the Join Features second. You may rename and delete unnecessary attributes. You will need to keep the fields relating to stream order, change in elevation and the length of the polyline features. (There are two Shape_Length attributes from the join so figure out where they come from.) Create a new field called “PercentGradient” and use the “Calculate Field” tool to calculate the gradient for each stream segment using the change in elevation and the length of the stream segment. Streams with gradient &lt; 20% will be considered as “fish bearing”. Step 6: Next, we will use the ESRI basemaps to measure stream width for a sample of streams stratified by order. We will use the average stream width per order to approximate the width for all streams in the study area. (For example, if the average width of streams in order 1 is 30 m, all streams in order 1 will be assigned that width). Stream width is defined using the entire channel width, not just the part with water currently flowing through it. Use the examples below to guide you with your mapping. You should be able to see channels for streams in orders 2-4, but order 1 streams will likely not be visible. We will assign these streams an average width of 1 m. Note that there are more sophisticated methods to calculate stream width from a DEM! S4 Stream S3 Stream S2 Stream (it is barely visible) Measure 10-15 stream widths per order using the “Measure” tool on your toolbar and record these measurements in an excel document. When you are satisfied with your measurements calculate average width of each stream order. Use the shaded relief DEM and the stream network polyline to help you find some of the smaller order 2 streams. Step 7: In the “StreamNetwork_join” attribute table, create a new field called “StreamWidth”. We will use an ifelse statement to conditionally assign values to the stream width attribute depending on stream order. Select the “StreamWidth” column in the attribute table and click “Calculate”. In the “Calculate Field” tool, change the “Expression Type” to “Python”. To use Python in the tool we need to populate two fields. First, the top “Expression” field, which should read StreamWidth =. This is where we can call a function and define the inputs to the function. Here we have called the function reclass with the “StreamOrder” attribute as the input. Next, in the “Code Block” we need to define the reclass function, so that we can use it as part of an expression. Here we will use an ifelse statement to set the values of stream width based on stream order. Modify the following code and paste it into the “Code Block” (delete the square brackets before running). Verify the expression using the check button &gt; Apply. def reclass(Order): if (Order == 1): return [average stream width here] elif (Order == 2): return [average stream width here] elif (Order == 3): return [average stream width here] else: return [average stream width here] If you get an “Invalid Field” error it is because the variable in the “Expression Field” (between the two!) does not match a field in the attribute table. So make sure to match the name of the appropriate field. You can use the pre-generated Field names to generate your expression to make sure this step works, just double-click on one to add it to your expression. Q4. Submit a table of summary statistics of number of stream links, average stream length, width and percent gradient grouped by stream order. (10 points) Q5. What is the total length (meters) of the streams that have fish bearing potential? (4 points) Task 3: Mapping Watersheds and Riparian Management Areas Step 1: Use the following table to assign a stream class (S1-S6) based on average channel width and fish bearing potential. Once a stream class is assigned, the Reserve Zone defines the region around the stream where harvest is prohibited and the Management Zone defines the region where limited harvest is permitted. Note that not all stream classes may be present in the dataset. (We do not have the S1 large rivers class in the study area so no need to include it.) In the “StreamNetwork_join” layer, create a new attribute called “Reserve_BufferDist” and set the “Number Format” to “Numeric”. Select the “Reserve_BufferDist” field in the attribute table and open the “Calculate Field” tool. Change the “Expression Type” to “Python”. This time we will combine the ifelse syntax from the previous task with conditional statements using stream gradient and width to assign buffer distances for each stream class. The example below defines the Reserve Zone buffer distance of 0m for the S1 class using the stream gradient and stream width attributes. The Reserve Zones and Management Zones are typically measured from the edge of the stream channel, however our streams are represented as lines down the centre of the stream channel. Think of a way to modify the buffer distances given in the table to reflect the approximate width of the stream. Your code should look something like the following. Make sure the highlighted attribute names in the Expression field match the names in your table, depending on how you named your columns they may look slightly different than this screenshot!: Use the following template in the “Code Block” to calculate the buffer distance for the remaining Reserve Zones (S1-S6). For classes with a width of 0 set the buffer distance to 0. def myCalc (gradient, width): if (gradient &lt; 20)and(width &gt;= 100): return 0 elif (gradient ...)and(width &gt; ... and width &lt; ...): ... else: return ... Repeat the same process for the Management Zone widths. Step 2: Open the “Buffer” tool and parameterize it as follows: Input Features: StreamNetwork_join Output Feature Class: Reserve_buffer Distance: Use drop-down menu to change to from Linear Unit to Field Reserve_BufferDist Side Type: Full End type: Round Dissolve: Dissolve all output features into a single feature Inspect the output. Repeat the Buffer step for the Management Zone widths. That is, first create a new field that captures the Management Zone widths in the table above. Then calculate a new field that represents the total of the stream + reserve + management buffer and create a new buffer that uses this value. Step 3: Next, we will map watersheds. A watershed is an area of land where all the water that falls or flows into it converges to a common outlet, such as a river, lake, or ocean. It is bounded by a drainage divide, which is a boundary that separates water flowing into different watersheds. The watershed tool uses flow direction and stream links to delineate watershed boundaries. The watershed boundaries will be defined such that water flows into each of the stream links. Open the “Watershed” tool and parameterize it as follows: Input D8 flow direction raster: Nahmint_FlowDir Input raster or feature pour point data: StreamLinks Output raster: Nahmint_watersheds The output will be a new raster where the cell values correspond to each unique watershed catchment. You should have something like the following (do not worry if it is not exactly the same as the screenshot): Step 4: Finally, we will create contour lines to help interpret the the DEM. Open the “Contour” tool and parameterize it as follows: Raster: Nahmint_DEM Output features class: Nahmint_contour Contour interval: 100 Base contour: [Set to the lowest elevation in the study area] Z factor: 1 Contour type: Contour Q6. How much forest area is retained within the Riparian Reserve and Management Zones? (4 points) Q7. How many watersheds are in the study area? (4 points) Q8. How did stream characteristics change across stream order? Is this what you expected? (10 points) Q9. Use the watershed map, contour lines and flow direction layers to assess how runoff from harvesting may impact stream networks. Reference specific areas/examples from the maps you created. Do you think the mapped RMAs provide adequate protection to streams in this area? Why or why not? (15 points) Q10. Discuss strengths and limitations of this workflow for determining riparian reserve and management zones. (10 points) Map 1. Upload a map that shows the stream network polylines (symbolized by stream class), watersheds, contours, an inset map showing example stream network and Riparian Management Areas, and text showing the total area in the Reserve and Management Zone and the length of the stream network. (25 points) Summary The aim of this lab was to practice solving a real-world forest management problem using raster and vector data. You have hopefully gained a thorough understanding of the tools available for modeling hydrology in ArcGIS Pro. In addition, the basemaps in ArcGIS Pro can be a valuable source of high-resolution satellite imagery. Be sure to stand up, stretch and drink some water! Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "],["time-series-image-analysis.html", "Lab: 7 Time Series Analysis Lab Overview Learning Objectives Deliverables Data Task 1: Calcualting NDVI from a Landsat image Task 2: Time Series Analysis Task 3: Change Detection Summary", " Lab: 7 Time Series Analysis Written by Nicholas Coops Lab Overview In this lab, we will be using Landsat derived Best Available Pixel (BAP) imagery to examine changes in the Malcom Knapp Research Forest over a 19-year time span. In Task 1 you will use the “raster calculator” to calculate NDVI across the study area. In Task 2, you will use ArcPro to visualize a multidimensional NDVI data set and create a temporal profile. In task 3, you will conduct a change detection between two NDVI layers. Learning Objectives Use Raster Functions tool to calculate NDVI in ArcGIS Interpret the physical meaning of regions of high, medium, and low NDVI Visualize temporal NDVI data in ArcGIS Create a temporal profile to help quantify changes in the image Use the change detection wizard to determine the difference in NDVI from 2000-2019 Deliverables Answers to the questions posed throughout the lab 2 Screenshots Data The data for this lab consists of a Landsat derived BAP imagery from the year 2000 – 2019. Information on this dataset and direction for downloading similar datasets can be found here: White, J.C.; Wulder, M.A.; Hobart, G.W.; Luther, J.E.; Hermosilla, T.; Griffiths, P.; Coops, N.C.; Hall, R.J.; Hostert, P.; Dyk, A.; et al. Pixel-based image compositing for large-area dense time series applications and science. Can. J. Remote Sens. 2014, 40, 192–212, doi:10.1080/07038992.2014.945827. https://github.com/saveriofrancini/bap Task 1: Calcualting NDVI from a Landsat image Step 1: Start a new ArcGIS Pro Map project and drag-and-drop the MKRF_UTM10S_2019_BAP.tif file into the map window. At this point, you should see an RGB satellite image of the Malcolm Knapp Research Forest (Figure 7.1) if the map view does not immediately pan to the image right click MKRF_UTM10S_2019_BAP.tif in the Contents pane and press Zoom to Layer. Figure 7.1: True colour composite of Malcom Knapp Research Forest (MKRF). Best Available Pixel Composites: To date, you have worked with single Landsat images acquired at one time. Oftentimes, there can be clouds or haze that obstruct parts of an image and reduce the amount of usable data from a single image acquisition. Best Available Pixel Composites address this issue by combining multiple images taken at different times into an “image stack” and creating a new image using only the best cloud-free pixels from the image stack. For this lab you are using a BAP composite created from images taken over the 2019 peak growing season. Q1. Why do you think BAP composites only use peak growing season imagery (July-August)? (5 points) Step 2: Spectral indices are mathematical equations containing spectral reflectance values from two or more wavelengths used to highlight areas of spectral importance in an image. There are a wide variety of spectral indices used to highlight a variety of different land covers and image properties including burned Areas (Normalized Burn Ratio), urban/ built up areas (Normalized Difference Built-Up Index), and water (Normalized Difference Water Index) to name a few. The Normalized Difference Vegetation Index (NDVI) is a frequently used spectral index that takes advantage of the high near-infrared reflectance and high red absorption properties of healthy vegetation and is therefore often used to quantify vegetation in a remotely sensed multispectral image. NDVI is calculated with the below formula: \\[ NDVI=\\frac{NIR-Red}{NIR+Red} \\] Where NIR is the near-infrared band (Landsat 7 Band 4) and Red is the red band (Landsat 7 Band 3). The results of this equation should be between -1 and 1 with values less than 0 representing water and values between 0-1 representing different levels of green vegetation. Navigate to the Imagery ribbon at the top of your ArcPro window and click the Raster Function button. The Raster Functions pane should appear, you can either navigate the drop-down menus to Math-&gt; Band Arithmetic or use the search function to find the Band Arithmetic Tool and click to open. The “Band Arithmetic Properties” dialogue should appear. Under “Raster” use the drop-down menu and select the MKRF_UTM10s_2019_BAP.tif layer. If it is not currently in your map view and can use the folder button and navigate to your lab data folder and select the file. Under “Method” select User Defined. It should look like the screen shot below. Use your knowledge of spectral indices and the NDVI formula given above to fill in the NDVI calculation for your data. “Create new layer” at the bottom of the window. The output should look something like Figure 7.2. Figure 7.2: Example output for the 2019 NDVI raster calculation for MKRF Q2. What are the minimum and maximum values of your new 2019 NDVI layer? (5 points) Q3. What information does this type of analysis give us? When and why might this type of analysis be used? (15 points) Task 2: Time Series Analysis In the previous section of this lab you calculated NDVI for an image of the Malcom Knapp Research Forest. In this section you will use a multidimensional dataset containing NDVI layers from 2000-2019 to create a temporal profile of NDVI change over time. Open the Catalogue pane and navigate to the lab data folder. Press the arrow for the data folder to expand. Click and drag the NDVI multidimensional data set into your map viewer. After opening the multidimensional dataset a new ribbon should appear at the top called Time along with a slider at the top of the map pane. Press the play button on the slider to start an animation of NDVI change over time. You can also click and drag the slider to view individual years. Q4. Hypothesize on what is causing the changes in NDVI? Why might the pattern in the south west corner of the timelapse look different from other changes? (15 points) Now that you have visualized the imagery, it is time to create a temporal profile help quantify the changes in the images. Right Click on the NDVI layer in the Contents pane and hover over “Create Chart” and select Temporal Profile. The “Temporal Profile” pane should appear on your screen, select “Properties” at the top of this pane. The “Chart Properties” pane should appear. Under “Time series” select “Multiple Locations with one variable” and select “Point” under area of interest. Your cursor should change into a coloured dot when hovering over the map pane. Clicking the left mouse button will select a pixel to view on your temporal profile. Use the Time slider animation function to find 4 changes that occur in different years, a 5th pixel representing water and a 6th representing an area with minimal change. See example bellow for possible locations but feel free to find and select your own. Click on Export in the Temporal profile pane and save your chart as a jpeg and submit it in your final report. Screenshot 1: Upload a screenshot of your temporal profile. (15 points) Q5. Examine your graph and provide some comments on the general trends you notice. Hypothesize on why different points take longer to recover or have smaller changes in NDVI values. (30 points) Q6. Examnine the line representing a water pixel. Does it have a consistant NDVI value? Explain why or why not? (15 points) Task 3: Change Detection Select the NDVI layer in the Contents pane, navigate to the Imagery ribbon and select Change Detection Wizard. A new pane should appear, under “Change Detection Method” select Pixel Value Change. Choose your NDVI multidimensional dataset as the “Input Raster”. “Variable” and “Dimension” should auto fill to NDVI and StdTime. Under “From Slice” select the year 2000 for “To Slice” select 2019 and press next. In the next window select Absolute under “Difference Type” and leave the remainder as default and press the Next button at the bottom. The “Classify Difference” pane should appear and you should see a histogram. Uncheck the “Classify the difference in values” button and then press next. Under “Smoothing Neighborhood” select 3x3 and set the “Statistics Fill Method” to median. Save your result as a raster dataset and under “Output Dataset” write “ChangeDetection_2000_2019” and press finish. Your results should appear in your map area. If you see a gray box right click the layer in the Contents pane and select “Symbology”. Under Primary symbology use the drop down menu and select Classify. You should now see an image on your screen that looks something like this: This output shows the difference in NDVI values between the 2000 and 2019 values close to zero mean that no change occurred while negative values represent a decrease in NDVI and positive values an increase in NDVI. Next, we will use the NDVI change layer to identify decreases in NDVI representing cut blocks. We are now going to use Geoprocessing tools to extract only the areas that have been identified. Navigate to the Analysis tab and select Tools &gt; Reclassify (Spatial Analyst Tools). The “Reclassify Window” should appear. Under the reclassification table press the Classify button and under “Number of Classes” write 2. The table should change and look like this: Change the “End” value in the first class to -0.05 and the “Start” value in the second class to -0.049999 and change the new field from 2 to NODATA. Run the tool. Your output should be a layer containing only pixels that had a negative change between the year 2000 NDVI image and the year 2019 NDVI image. Notice that some of the pixels you have retained are lakes. Since we are principally concerned with terrestrial vegetation it is common practice to remove pixels that represent water using a water mask. Masking can either be done as a pre-processing step or at the end of our analysis. Navigate to the “Analysis” ribbon and select Tools. Search for the tool “Extract by Mask”. Under “Input Raster” select your cutblock raster and under feature mask data navigate to the data folder and select the “LakeMask” file. Save your output as “NDVICutblocks” select run. Screenshot 2: Upload a screenshot showing the BAP true-color composite with the cut blocks identified from the NDVI image overlaid on top. (15 points) Summary Spectral Indices offer a unique ability to highlight landcover and image properties that would be very difficult to map without the use of spectral information. The Normalized Difference Vegetation Index (NDVI) has become one of the most widely used indices and thanks to satellite programs like Landsat, we now have access to global coverage of this index. In this lab, we explored the ability to derive this index from Landsat BAP data from 2000-2019 in ArcGIS and explore the temporal profile of NDVI to quantify changes in the image through time. We can use change detection tools to then be able to assess regions that have changed significantly through our time period. Time series data of spectral indices like NDVI can be game changing for many research applications like monitoring drought, agricultural productivity, and measuring biomass! Return to the Deliverables section to check off everything you need to submit for credit in the course management system. "]]
